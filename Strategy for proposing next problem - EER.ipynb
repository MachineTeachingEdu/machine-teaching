{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next sample strategy\n",
    "\n",
    "Considered strategies used to propose the next problem:\n",
    "1. Randomly sample from the dataset D. Does not model the student and is therefore unable to adapt to their ability. May present redundant teaching examples of concepts that have already been learned by the student and not reinforce concepts that the student has shown to be uncertain about.\n",
    "2. ~~Worst predicted. Related to uncertainty sampling used in Active Learning. Selects the next teaching image whose prediction deviates most from the ground truth. Prone to proposing outliers. In the learning to program problem, maybe it presents the hardest exercises?~~\n",
    "3. Expected Error Reduction. Chooses the teaching image which, if labeled correctly, would have the greatest reduction on the future error over the images that not in the teaching set. Student’s conditional distribution given the teaching set can be approximated using Gaussian Random Field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "from db import PythonProblems\n",
    "import io\n",
    "\n",
    "# Helpers\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "import tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Distance\n",
    "# from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Learning\n",
    "from clustering import Clustering\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = PythonProblems('python.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 758 documents\n",
      "Success in parsing all documents! You may go on!\n"
     ]
    }
   ],
   "source": [
    "removed_itens = ['NEWLINE', 'STRING', 'ENDMARKER', 'NUMBER', 'INDENT', 'DEDENT', \"NL\", 'COMMENT', 'ERRORTOKEN']\n",
    "allowed_itens = ['NAME', 'OP']\n",
    "cursor = db.conn.cursor()\n",
    "docs = []\n",
    "docs_id = []\n",
    "errors = []\n",
    "\n",
    "# lendo os dados\n",
    "cursor.execute(\"\"\"\n",
    "SELECT * FROM solution;\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "for idx, row in enumerate(cursor.fetchall()):\n",
    "    file = io.StringIO(row[1])\n",
    "    doc = []\n",
    "    try:\n",
    "        for item in tokenize.generate_tokens(file.readline):\n",
    "            if tokenize.tok_name[item[0]] not in removed_itens:\n",
    "                if tokenize.tok_name[item[0]] in allowed_itens:\n",
    "                    doc.append(item[1])\n",
    "                else:\n",
    "                    print(\"%s %s\" % (tokenize.tok_name[item[0]], item[1]))\n",
    "    except (IndentationError, tokenize.TokenError):\n",
    "        errors.append(\"Please, fix solution %d before continuing\" % (idx+1))\n",
    "    \n",
    "    if doc == []:\n",
    "        continue\n",
    "    docs.append(' '.join(doc))\n",
    "    docs_id.append(row[0])\n",
    "\n",
    "print(\"Got %d documents\" %(idx+1))\n",
    "\n",
    "if not errors:\n",
    "    print(\"Success in parsing all documents! You may go on!\")\n",
    "else:\n",
    "    for item in errors:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Limitação do parser: variável e nome reservado são do mesmo tipo. Não consigo separar sem fazer uma pré-lista. Mas pode ser o critério para ajustar o CountVectorizer***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing solutions into bag of words ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "#                              stop_words = ['print'],   \\\n",
    "                             #max_features = 26d,\n",
    "                             binary=False,\n",
    "                             min_df=0.1\n",
    "                            ) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "# Document-term matrix\n",
    "train_data_features = train_data_features.toarray()\n",
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows containing only zeros (weird exercises)\n",
    "solution_sample = train_data_features[~(train_data_features==0).all(1)]\n",
    "solution_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-408987534924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'im' is not defined"
     ]
    }
   ],
   "source": [
    "max_value = np.iinfo(im.dtype).max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint() takes at least 1 positional argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-15cbd58e73ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_topic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_mixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_topic_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/machine-teaching/clustering.py\u001b[0m in \u001b[0;36mgaussian_mixture\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgaussian_mixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;34m\"\"\" Use gaussian mixture clustering method \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         model = GaussianMixture(n_components=self.k,\n\u001b[1;32m     98\u001b[0m                                 random_state=self.seed).fit(self.X)\n",
      "\u001b[0;32m~/Documents/machine-teaching/clustering.py\u001b[0m in \u001b[0;36m_generate_random_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_generate_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_normalize_per_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: randint() takes at least 1 positional argument (0 given)"
     ]
    }
   ],
   "source": [
    "clustering = Clustering(solution_sample, 8)\n",
    "model, document_topic, word_topic = clustering.gaussian_mixture()\n",
    "print(clustering.seed)\n",
    "clustering.plot_topic_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MT19937', array([3942021341, 2559610341, 2123749344, 3595353302,  715861058,\n",
       "        3299072022, 3183130135, 1454888680, 3944312100, 1578715672,\n",
       "        1770395631, 2817084010, 4065991960,  998893951, 3747417617,\n",
       "        2776650171, 3033526613, 2890586051, 1676908266, 2691748698,\n",
       "         455818622,   11214744, 2184360402, 2913938233, 3559966712,\n",
       "        1333355922, 2929333120, 2898482206,  912746822,  887660006,\n",
       "        1789997247, 3236539593,  794971692, 3375499849, 1843235110,\n",
       "        3583850294, 2426568665,  446157486, 1536518304,  464736729,\n",
       "        1520325815,  517844199, 4106350485, 4153203273,  373954747,\n",
       "        1514693647, 3615968301, 1228900934, 2285555994,  724164763,\n",
       "        1200532938, 2148762603, 2514608337,  268640701,  605935513,\n",
       "        2151103382,  268564224,  312501461, 3106491200, 1544251668,\n",
       "        2336427691,   95570662, 2543730734,  753625785,  614608804,\n",
       "        1762099558,  335798844, 3747188108, 3592145145, 3732927897,\n",
       "         233955420, 3261324781,  804590563,  979415224, 2150834623,\n",
       "        3911016932,  951553211, 3730425095, 1769711344, 3498785916,\n",
       "         128884544, 1932294354,  872302857, 1014618393,  957030515,\n",
       "         969542988, 3400156141, 4263565864, 1197446238, 4184875072,\n",
       "        2838273530, 2022985950, 3705105811, 2029128106, 1128962586,\n",
       "        1327227774, 2668609340,  686228415, 2572364111, 3384392539,\n",
       "        3018085915, 3226302026, 3925218979, 3824077243, 2567084033,\n",
       "        2613298733, 3703084297, 2940835622, 1777876352, 1632856658,\n",
       "        3093722244, 1397406793, 1079475496, 2194081935,  992855448,\n",
       "         217886438, 1216871382, 4006470286, 3711384264,   38711603,\n",
       "         991611112, 2896822258,  340415021, 3426849064,  148009959,\n",
       "        1058257872,  963071924, 2788295755, 1592013427, 1099412757,\n",
       "        3574391598, 2165145294,  473003541, 3753042422, 2773023568,\n",
       "         157923868, 1205499962, 1823023347, 3137211356, 3903937006,\n",
       "        2083302804, 3615036997,  708704106,    3952281, 3976461408,\n",
       "         308802472, 3930548938,  506855886, 2635057799, 3988190176,\n",
       "        1393991316,  195622211, 2996122867, 3157216864, 3831819010,\n",
       "        3255965514, 4110004131, 2496056349, 3427568830,  316829253,\n",
       "        2895736004, 2417406578, 1825882064, 2801553756, 4198310387,\n",
       "        3654620791,   15635095,  105776089,  440478544, 4048141673,\n",
       "        2973677652, 2791957586, 1047381736, 2509347133, 3884119968,\n",
       "        1672077277, 2866137201, 3796692614, 2976251240, 1332977545,\n",
       "          48887299, 4260074793,  565937015,  271324076,  723448179,\n",
       "        4134424838,  946908826, 3239798731, 2942933066, 1879432041,\n",
       "        1939332205, 2557158625, 2508431376,  424075674,  699964986,\n",
       "         916556547,  484579805,  833200167,  722823253, 4176286540,\n",
       "        3702542113, 3973352690, 3683981222, 3153498798,  890113418,\n",
       "        3551535272, 1168415954, 2529688731, 3086640688, 2213635875,\n",
       "        1506656054, 3922289254, 2421075781, 1136133767,  798066632,\n",
       "          92376047, 1604888269, 2747051732, 4216908174, 1820984242,\n",
       "        3007888694, 3314576202, 2131280387, 1443331039, 1342159869,\n",
       "        3141566593, 1124307893,  804300782, 3672514118, 1329585695,\n",
       "        1985683715, 1287190242, 1069196405, 1774175079, 2997369029,\n",
       "        3636251648, 3058696852,  814078495,  223037797, 3045943179,\n",
       "        2711374744, 3169215547, 3599475490, 2195579634, 3813911261,\n",
       "        2033243693,  951129886, 3743242478, 3968196772,  917744191,\n",
       "         480648771, 2309451682,  270335400,  870626975,  150381150,\n",
       "        1445505557,  911358522,  649132099,  161204623,  274955419,\n",
       "        2998988422, 1451090595,  540608483, 2649944735, 4179571205,\n",
       "         449892751, 3121669791, 1872853370, 3043221010, 3319805417,\n",
       "         446446874, 1867429600, 2740945292,  679862029, 4215648349,\n",
       "        3072998431, 2599501116, 1698981338, 3463152117, 1868828291,\n",
       "        2460661145, 2427476561, 2084345252, 3282648783, 3724994891,\n",
       "        3075355478,  890856601, 1050844268, 3202111777, 3757671796,\n",
       "        1412373289, 3621487728, 1380487258, 1160804982, 2523880868,\n",
       "        2815555684, 3177175876, 3091104705, 1982023147,   83642371,\n",
       "        2014614772, 1212850388,  429925790, 3768849296, 2628520195,\n",
       "        1293145893, 1240569449,  375519865, 2657898571, 1789703719,\n",
       "         870570239, 1575280343, 1331295151,  780122473,   39287124,\n",
       "        2795358760, 1403815847, 2187309303, 3781362824, 1897923999,\n",
       "        4237182802, 2144033266, 4197364026, 2085367168, 3027202107,\n",
       "         603867699, 3216979936, 2606715114,  162271883,  449076077,\n",
       "        2331468879, 2059834013, 1982925347, 3948835927, 2324943530,\n",
       "         109465781, 1486830742, 4158740704, 3615916416, 1802454060,\n",
       "         452515282, 2856702357, 2810530437, 1386427093, 1901994882,\n",
       "        1286050657, 4064226962, 1240582217, 2369576079, 3216167844,\n",
       "        1033339141, 3925797939, 2964878215, 1302963949,  221176737,\n",
       "        1431443544, 2018651323,  529381613,   91993945, 3046945301,\n",
       "        3908401126,  614448159, 1421733879, 1041628951, 1382216675,\n",
       "        1668089199,  638988942, 4145208203,  694072742, 2405522594,\n",
       "         756921436, 1175245397, 2542101364, 3896634577, 2354834651,\n",
       "        3314310467, 2102788220, 3855728600,   75067428, 3284427593,\n",
       "         660633440, 3212174094,  820198876, 3993108239,  312867969,\n",
       "        2635818376, 3789567402, 4131567245, 3314880750, 1674764805,\n",
       "         265435440, 4094813430, 2057056596, 2802804259, 3796293661,\n",
       "        4112838836, 3659086397,  928569606, 3692704094, 4092481707,\n",
       "        3769817549, 3482926140, 2373956483, 1819043280, 2043443813,\n",
       "        1072066458, 3057657770, 4221171196, 3746219369, 4092343967,\n",
       "        2353644586, 1734968851,  962074101, 2750797827, 1960759867,\n",
       "        2430056231,  979297744, 3014592071, 3336581326, 3626936799,\n",
       "        1108968875, 1656208337, 3658433005, 2991336861, 1777017840,\n",
       "         455302804, 2751318442, 3765478037,  549036096, 3793989360,\n",
       "        4027936017,  884768961, 3277926411,  882053480,    7098667,\n",
       "        1576098300, 1508970097, 3559287699, 1128933284,  427730672,\n",
       "        1893411955, 1506969771, 1864457515, 1738957378, 2235107105,\n",
       "        4226850041, 1359537902, 3436092267, 1796643444, 1634766070,\n",
       "        1689927690, 2087836684, 3067030475,  460980821, 2153056091,\n",
       "        2216732815, 1593499669, 3215186595, 3945818539, 3493391437,\n",
       "        1590503349, 1986884585, 1864301720,  785177630, 1630609815,\n",
       "        3943345654, 3018934702,  493586120, 1695221504,  245353451,\n",
       "        2292752857,  383144469,  567551363, 3859966196, 1978853214,\n",
       "         468801735,  478993702, 4283498845, 3409477419, 3781278617,\n",
       "         639975493, 1651924200, 2715471042, 2578811899, 2058322882,\n",
       "        2007873399, 3869690604, 3253082076, 2193502313,  258770389,\n",
       "         469705360, 3730129217, 1908556150, 2632206884, 3934836632,\n",
       "        3705738174, 2290566771, 1049310664,  871067880, 2264064184,\n",
       "         409541847, 2328348337, 2372323934, 2929724958, 1423253357,\n",
       "         174003817, 3173047864, 1669929233, 1021684631, 2635174943,\n",
       "        3859238379,  140455644, 1178816840, 4134958659, 2133392424,\n",
       "         979520481,  824901902, 4218230938, 2446289375, 2771476133,\n",
       "        3528659816, 3452344286, 1193399454, 2389249357, 1772254074,\n",
       "        4034682980, 2838655234, 3203352472,  654803058, 2388278518,\n",
       "        1682131689,  930555407,  202203879, 1429849336, 3481191017,\n",
       "         787484269, 3712342529,  741578877, 3796469063, 2581178488,\n",
       "        3337214474,  104836186, 3665181548,  449271430,  654595840,\n",
       "         698560375, 2462186788,  305165923, 3943255869, 4152438572,\n",
       "         829005943, 3361313268,  595835222, 2597071409, 2002071535,\n",
       "        2068836426, 3691429903, 3319214928, 1467419463, 2054568392,\n",
       "        3745590945, 2327624987, 1475777958, 3964535599, 1829640322,\n",
       "        4109428347,  241234144, 1066672483, 1224130391,  406073174,\n",
       "        1816668722, 1245903476, 3531667090,  602092635, 3889277173,\n",
       "        2060400940, 3520572120, 1297086581, 1287434291, 1778004373,\n",
       "        2287996137, 3448648464, 2112637938, 2951053992, 3847033445,\n",
       "        3105055095, 3037750549, 3807672878,  628782839, 4287909957,\n",
       "        3138693148, 1521027281,  466377503, 3147034290,  187512518,\n",
       "        2256738010, 2443173583,  877903098, 3689327292, 1671738055,\n",
       "         491995705, 1970403047,  891821034, 2362569571, 3729548678,\n",
       "         530602437,  364713749,  168402437, 1449607671, 3835794457,\n",
       "        1442459248, 2972844328, 3205357851, 4099847549, 2243611431,\n",
       "        4204671983, 3788053054, 1476660986, 1598636576, 3721638149,\n",
       "        3273354659, 1278540410, 1312986322, 2859720111], dtype=uint32), 624, 0, 0.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.RandomState().get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get next sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create X as an empty belief state (X is the machine's model of the student's distribution)\n",
    "X = numpy.zeros(solution_sample.shape[0], )\n",
    "# Save X\n",
    "X_path = os.path.join('../User-Data/X_' + str(user_id) + '.npy')\n",
    "numpy.save(X_path, X)\n",
    "# Set L as an unlabelled set\n",
    "L = []\n",
    "request.session['L'] = L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Date: June 2015\n",
    "# Author: Edward Johns (e.johns@imperial.ac.uk)\n",
    "# This code may be freely distributed, but citations should be made to:\n",
    "# E. Johns et al, \"Becoming the Expert - Interactive Multi-Class Machine Teaching\", in Proceedings of CVPR 2015\n",
    "########################################################################\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_next_sample(X, Y, W, L):\n",
    "\n",
    "    # Based on \"Zhu et al., Combining Active Learning and Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions, in ICML workshop 2003\"\n",
    "\n",
    "    # Input:\n",
    "    # Below, nS = total number of samples, nC = number of classes, nL = number of observed samples, nT = total number of testing samples to be shown to user\n",
    "    # X: nS*nC belief matrix, with each row representing one sample, and each column representing one column. Each element is the probability that the user thinks that sample is assigned to that class. This would be identical to Y if we were assuming that the user always assigns the ground truth to an observed sample, and never has memory fall-off.\n",
    "    # Y: nS*nC ground truth matrix (NumPy array), with each row in indicator encoding. This represents the ground-truth labels of all points. As such, each row has only one \"1\" and all other entries are \"0\".\n",
    "    # W: nS*nS graph weights matrix (symmetrical NumPy array), with each row and each column corresponding to one sample. Each element is the weight (affinity) between two samples.\n",
    "    # L: nL*1 labeled set, where each element is one sample that has already been shown to the user, with indices between 1 and nS.\n",
    "    # testing_samples: nT*1 testing set, where each element is one sample that will (or has already been) shown to the user as a testing image. This is to prevent testing images being shown during teaching.\n",
    "    # mode: the teaching mode (2 = worst predicted, 3 = our method)\n",
    "    # Output:\n",
    "    #    next_sample: the index of the optimum sample to be shown next, as selected by the active teaching algorithm.\n",
    "\n",
    "    # Get the total number of samples (nS) and total number of classes (nC). nC is not actually used.\n",
    "    [nS, nC] = X.shape\n",
    "\n",
    "    # Create the set of unlabelled samples (U)\n",
    "    U = np.setdiff1d(np.arange(nS), L)\n",
    "\n",
    "    # Get the number of unlabelled samples (nU)\n",
    "    nU = len(U)\n",
    "\n",
    "    # Get the ground truth for the unlabelled samples\n",
    "    Yu = Y.take(U, 0)\n",
    "\n",
    "    # Get the unlabelled section of the covariance matrix\n",
    "    Delta = np.subtract(np.diag(np.sum(W, 1)), W)\n",
    "    invDeltaU = np.linalg.inv(Delta.take(U, 0).take(U, 1))\n",
    "\n",
    "    # Get the current state of the GRF, for the unlabelled samples\n",
    "    f = np.dot(invDeltaU, np.dot(W.take(U, 0).take(L, 1), X.take(L, 0)))\n",
    "\n",
    "    # Create a list of risks, one for each unlabelled sample\n",
    "    uRisks = np.zeros(nU)\n",
    "\n",
    "    # Try each unlabelled sample\n",
    "    for u in range(nU):\n",
    "        # Find the sample number (remember that U is just the list of unlabelled samples, not all the samples)\n",
    "        s = U[u]\n",
    "\n",
    "        # If the sample is a testing image, then ignore it (by assigning a very high risk)\n",
    "        if s in testing_samples:\n",
    "            uRisks[u] = 10000\n",
    "            continue\n",
    "\n",
    "        # Calculate the new state of the GRF if this sample were to be revealed to the user (here, we assume that the user's belief of this sample will then be the ground truth -- debatable...)\n",
    "        GG = invDeltaU[:, u] / invDeltaU[u, u]\n",
    "        diff = Y[s, :] - f[u, :]\n",
    "        fPlus = f + np.dot(GG[..., np.newaxis], diff[np.newaxis, ...])\n",
    "\n",
    "        # Sum up the risks over all unlabelled points (i.e. the difference between the new state, and the ground truth)\n",
    "        D = np.abs(1 - fPlus[Yu == 1])\n",
    "        uRisks[u] = np.sum(D)\n",
    "\n",
    "    # Get the sample which minimised the risk\n",
    "    next_sample_index = np.argmin(uRisks)\n",
    "    next_sample = U[next_sample_index]\n",
    "\n",
    "    # Return this sample\n",
    "    return next_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate similarity matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get pairwise similarity\n",
    "dist = cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] Johns, E., Aodha, O. Mac & Brostow, G. J. Becoming the expert - Interactive multi-class machine teaching. in Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (2015). doi:10.1109/CVPR.2015.7298877\n",
    "\n",
    "[2] Zhu, X., Lafferty, J. & Ghahramani, Z. Combining Active Learning and Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions Xiaojin. … Data Mach. Learn. … (2003)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
