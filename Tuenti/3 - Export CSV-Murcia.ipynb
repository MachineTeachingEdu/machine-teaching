{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordlist = pd.read_pickle('wordlist.p')\n",
    "models = pd.read_pickle('tuenti_models.p')\n",
    "docs_df = pd.read_pickle('tweets_tuenti_tokenized.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_terms(data, wordlist):\n",
    "    components = data['model'].components_\n",
    "    words = np.argsort(-1*components, axis=1)[:,:20]\n",
    "    np_wordlist = np.array(wordlist)\n",
    "    \n",
    "    return np_wordlist[words].tolist()\n",
    "\n",
    "def print_terms(data, wordlist):\n",
    "    terms = get_terms(data, wordlist)\n",
    "    \n",
    "    for idx_topic, terms_topic in enumerate(terms):\n",
    "        print(\"%3d: %s\" % (idx_topic, \" \".join(terms_topic)))\n",
    "        \n",
    "def get_tweets(data, cluster, tweets):\n",
    "    clusters = np.argmax(data['V_T'], axis=1)\n",
    "    cluster_tweets = tweets[clusters == cluster]\n",
    "    return cluster_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: vete casa olvida line cara nombre insta facebook twitter vas despues bloquean eliminan cartas ðŸ˜‚ todas ninos madre historia sociales\n",
      "  1: mira empezo mismo acabo usaba vale meter acuerdo whatsapp muerto ponia siguenos muero jaja permite moviles ðŸ˜‚ reaccion diego @youtube\n",
      "  2: facebook sigue caido twitter chica redes haciendo mierda ir gusta primero par cosas anos vas despues clase bloquean cartas eliminan\n",
      "  3: face visto deberia ayer haber foto insta alguna antiguo subo jaja xd acuerdas habia nueva conozco pareces actualizacion vez tia\n",
      "  4: madrid proximity trabajar comienza sigo dejar md fav mensaje vez habia nueva tia actualizacion encanta mirar jaja mejor recuerda hablamos\n",
      "  5: pues verguenza horas hecho tiempo xd sera nuevo recuerdos red social ajena parte entrado meo despues vida twitter ðŸ˜‚ madre\n",
      "  6: persona google buenos myspace dar dias nivel conoce cuenta facebook twitter nuevo novio llevo meterse viendo fotos hice lloro msn\n",
      "  7: hace falta hora instagram fotos gente viendo casi anos volver metido guapa chonis poniendo vida generacion fotolog doy nuevo historia\n",
      "  8: sociales ahi funciona nunca redes dia todas badoo vida quisiera puta luz dio epoca jaja twitter ðŸ˜‚ fotos buena chat\n",
      "  9: muero eramos grande tarde risa ðŸ˜‚ fotos siguenos ponia encuentra ðŸ˜­ entrar vuelve jaja meter usaba vale conversaciones msn lloro\n"
     ]
    }
   ],
   "source": [
    "print_terms(models[10], wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('tweets_murcia.xlsx')\n",
    "terms = get_terms(models[10], wordlist)\n",
    "topics = []\n",
    "for idx_topic, terms_topic in enumerate(terms):\n",
    "    topics.append((\"Topic %d\" % (idx_topic+1), \", \".join(terms_topic)))\n",
    "    \n",
    "terms_df = pd.DataFrame(topics)\n",
    "terms_df.to_excel(writer, \"Terms x Topic\", index=False, header=[\"Topic\", \"Terms\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    docs_topic = get_tweets(models[10], i, docs_df)[['text', 'screen_name']].drop_duplicates('text', inplace=False)\n",
    "    docs_topic.to_excel(writer,'Topic %d' % (i+1), index=False, columns=['screen_name', 'text'], header=['user', 'tweet'])\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
