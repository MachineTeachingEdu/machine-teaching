{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tokenizer import create_bag_of_words\n",
    "\n",
    "# DB\n",
    "from django.db.models import Case, IntegerField, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_id = 132\n",
    "problems = Problem.objects.filter(id__lte=last_id)\n",
    "user_blacklist = UserProfile.objects.filter(professor__user__username='sem_professor')\n",
    "\n",
    "attempts = UserLog.objects.exclude(outcome='S').filter(\n",
    "    timestamp__lt=OuterRef('timestamp'), user__id=OuterRef('user__id')).annotate(\n",
    "    attempt=Count('*')).values('attempt')\n",
    "\n",
    "# Remove group by values\n",
    "attempts.query.set_group_by()\n",
    "\n",
    "# Get users\n",
    "users = UserLog.objects.filter(problem__in=problems).exclude(outcome='S').exclude(\n",
    "    user__userprofile__in=user_blacklist).annotate(\n",
    "    attempt=Subquery(attempts, output_field=IntegerField())).annotate(\n",
    "    score=Case(\n",
    "        When(outcome='F', then=Value(0)),\n",
    "        When(outcome='P', then=Value(1)),\n",
    "        output_field=IntegerField())).values_list(\n",
    "    \"user__id\", \"solution\", \"attempt\", \"score\"#\"outcome\", \"timestamp\"\n",
    ").order_by(\"timestamp\").filter(attempt=1).values_list('user_id', flat=True)\n",
    "\n",
    "solutions_obj = UserLog.objects.filter(problem__in=problems).exclude(outcome='S').annotate(\n",
    "    attempt=Subquery(attempts, output_field=IntegerField())).annotate(\n",
    "    score=Case(\n",
    "        When(outcome='F', then=Value(0)),\n",
    "        When(outcome='P', then=Value(1)),\n",
    "        output_field=IntegerField())).annotate(resource=Value(0,  IntegerField())).values(\n",
    "    \"user__id\", \"solution\", \"attempt\", \"score\", \"resource\"#\"outcome\", \"timestamp\"\n",
    "                                                                    ).order_by(\"timestamp\").filter(user__in=users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3632"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solutions_obj.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solutions to be used: 3632\n",
      "Got 3632 documents\n"
     ]
    }
   ],
   "source": [
    "print(\"Solutions to be used: %d\" % solutions_obj.count())\n",
    "\n",
    "# docs_id = []\n",
    "# questions = []\n",
    "solutions = []\n",
    "student_attempt = defaultdict(int)\n",
    "\n",
    "# Fill separated structures\n",
    "for idx, attempt in enumerate(solutions_obj):\n",
    "#     user_ids.append(attempt[\"user__id\"])\n",
    "#     questions.append(attempt.problem.content)\n",
    "    solutions.append(attempt[\"solution\"])\n",
    "    student_attempt[attempt[\"user__id\"]] += 1\n",
    "\n",
    "print(\"Got %d documents\" %(solutions_obj.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = CountVectorizer\n",
    "b = True\n",
    "m = 0.05\n",
    "vectorizer_params={'ngram_range': (1,3)}\n",
    "train_data_features, vectorizer, feature_names = create_bag_of_words(solutions, v, binary=b, min_df=m, \n",
    "                                                                     vectorizer_params=vectorizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3632, 285)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = solutions_obj.order_by('user').values('user').distinct('user')\n",
    "users = list(users.values_list('user', flat=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 ms, sys: 164 Âµs, total: 19.8 ms\n",
      "Wall time: 943 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_attempt': 0,\n",
       " 'max_attempt': 265,\n",
       " 'avg_attempt': 28.02340308370044,\n",
       " 'median_attempt': 13.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "attempt_stats = solutions_obj.aggregate(min_attempt=Min('attempt'), \n",
    "                                    max_attempt=Max('attempt'), avg_attempt=Avg('attempt'))\n",
    "attempts_list = solutions_obj.values_list(\"attempt\", flat=True)\n",
    "attempt_stats['median_attempt'] = np.median(attempts_list)\n",
    "attempt_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STUDENTS = len(users)\n",
    "N_TERMS = train_data_features.shape[1]\n",
    "N_ATTEMPTS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_performance = np.zeros((N_STUDENTS, N_TERMS, N_ATTEMPTS))\n",
    "student_performance_fdtf = np.zeros((N_STUDENTS, N_TERMS, N_ATTEMPTS))\n",
    "# X = np.ones((N_STUDENTS, N_TERMS, N_ATTEMPTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data features is ordered by user by timestamp\n",
    "# No problem in iterating through it\n",
    "student_attempt = defaultdict(int)\n",
    "for idx, row in enumerate(train_data_features):\n",
    "    # Actual user id\n",
    "    user_id = solutions_obj[idx][\"user__id\"]\n",
    "#     print(\"Attempt %d for user %d\" % (student_attempt[user_id], user_id))\n",
    "    # User index in the users list\n",
    "    user_idx = users.index(user_id)\n",
    "    # Update tensor, if ATTEMPT is higher than allowed, discard it\n",
    "    if student_attempt[user_id] < N_ATTEMPTS:\n",
    "        student_performance[user_idx, :, student_attempt[user_id]] = row\n",
    "        row_fdtf = row.copy()\n",
    "#         X[user_idx, :, student_attempt[user_id]][row_fdtf == 0] = 0\n",
    "        row_fdtf = row_fdtf * solutions_obj[idx][\"score\"]\n",
    "        student_performance_fdtf[user_idx, :, student_attempt[user_id]] = row_fdtf\n",
    "    student_attempt[user_id] += 1\n",
    "    \n",
    "student_performance_fdtf[np.where(student_performance[:,:] == 0)] = None\n",
    "\n",
    "original_sp = student_performance.copy()\n",
    "original_sp_fdtf = student_performance_fdtf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\n",
      "Run: 1\n",
      "Run: 2\n",
      "CPU times: user 21min 32s, sys: 44.2 s, total: 22min 16s\n",
      "Wall time: 11min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "215.03525993206188"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "best_student_performance_pred, best_student_knowledge, best_q_matrix, best_error = als_tensor_factorization(\n",
    "    student_performance, n_concepts=12, init=3, max_iter=1000)\n",
    "best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0\n",
      "Run: 1\n",
      "Run: 2\n",
      "CPU times: user 20min 49s, sys: 51.6 s, total: 21min 40s\n",
      "Wall time: 10min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "968.1343567320796"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "student_performance_fdtf = original_sp_fdtf.copy()\n",
    "best_student_performance_pred, best_student_knowledge, best_q_matrix, best_error = feedback_driven_tensor_factorization(\n",
    "    student_performance_fdtf, n_concepts=7, init=3, max_iter=1000, mu=3)\n",
    "best_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.22%\n",
      "RMSE: 0.51\n"
     ]
    }
   ],
   "source": [
    "bspp_binary = best_student_performance_pred.copy()\n",
    "bspp_binary[bspp_binary > 0.5] = 1\n",
    "bspp_binary[bspp_binary < 0.5] = 0\n",
    "\n",
    "y = student_performance[np.where(student_performance[:,:] == 0)]\n",
    "y_pred = best_student_performance_pred[np.where(student_performance[:,:] == 0)]\n",
    "y_pred_binary = bspp_binary[np.where(student_performance[:,:] == 0)]\n",
    "\n",
    "# best_student_performance_pred[best_student_performance_pred > 0.5] = 1\n",
    "# best_student_performance_pred[best_student_performance_pred < 0.5] = 0\n",
    "\n",
    "acc = 100*(np.logical_not(np.logical_xor(\n",
    "    y, y_pred_binary)).sum())/len(y)\n",
    "rmse = np.sqrt(np.power((y-y_pred), 2)).mean()\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % acc)\n",
    "print(\"RMSE: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coherence import calculate_uci_npmi_coherence_all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get new solutions\n",
    "problems = Problem.objects.exclude(chapter=None)\n",
    "new_solutions = list(Solution.objects.filter(problem__in=problems, ignore=False\n",
    "                                            ).order_by('id').values_list('content', flat=True))\n",
    "\n",
    "test_data_features = vectorizer.transform(new_solutions).toarray()\n",
    "test_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load coherence.py\n",
    "from itertools import permutations, combinations\n",
    "def calculate_uci_npmi_coherence(X, word_topic, clusters, k, N=5):\n",
    "    \"\"\" Calculates NPMI for the top-N words using an external dataset.  \"\"\"\n",
    "    k_pmi = []\n",
    "    count_data = X.copy()\n",
    "    # Transform to binary count\n",
    "    count_data[np.where(count_data != 0)] = 1\n",
    "\n",
    "    # For each cluster, calculate PMI\n",
    "    for idx_cluster in range(0, k):\n",
    "\n",
    "        cluster_data = count_data[clusters == idx_cluster]\n",
    "\n",
    "        # If there aren't any documents assigned to the cluster, skip it\n",
    "        if cluster_data.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate cooccurence matrix\n",
    "        cooccurence = np.dot(cluster_data.T, cluster_data)\n",
    "\n",
    "        # For each topic, get N top words\n",
    "        idx = word_topic[:,idx_cluster].argsort()[::-1][:N]\n",
    "        total = cooccurence[idx,:][:,idx].diagonal().sum()\n",
    "        combs = combinations(idx, 2)\n",
    "        k_score = []\n",
    "        for i,j in combs:\n",
    "            if cooccurence[i,i] == 0 or cooccurence[j,j] == 0:\n",
    "                #print(np.where(clusters == idx_cluster))\n",
    "                #print(cooccurence[idx,:][:,idx])\n",
    "                raise RuntimeError(\"Some words do not occur in topic %d. Choose a smaller number of N.\" %\n",
    "                                   idx_cluster)\n",
    "            p_i = cooccurence[i,i]/total\n",
    "            p_j = cooccurence[j,j]/total\n",
    "            p_i_j = cooccurence[i,j]/total\n",
    "            score = np.log((p_i_j+0.001)/(p_i * p_j))/-np.log(p_i_j+0.001)\n",
    "            k_score.append(score)\n",
    "        k_topic = np.mean(np.asarray(k_score))\n",
    "        k_pmi.append(k_topic)\n",
    "    return k_pmi, np.mean(k_pmi), np.std(k_pmi)\n",
    "\n",
    "\n",
    "def calculate_uci_npmi_coherence_all_docs(X, word_topic, clusters, k, N=5):\n",
    "    \"\"\" Calculates NPMI for the top-N words using an external dataset.  \"\"\"\n",
    "    k_pmi = []\n",
    "    count_data = X.copy()\n",
    "    # Transform to binary count\n",
    "    count_data[np.where(count_data != 0)] = 1\n",
    "\n",
    "    # For each cluster, calculate PMI\n",
    "    for idx_cluster in range(0, k):\n",
    "\n",
    "        cluster_data = count_data[clusters == idx_cluster]\n",
    "\n",
    "        # If there aren't any documents assigned to the cluster, skip it\n",
    "        if cluster_data.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # Calculate cooccurence matrix\n",
    "        cooccurence = np.dot(count_data.T, count_data)\n",
    "\n",
    "        # For each topic, get N top words\n",
    "        idx = word_topic[:,idx_cluster].argsort()[::-1][:N]\n",
    "        total = cooccurence[idx,:][:,idx].diagonal().sum()\n",
    "        combs = combinations(idx, 2)\n",
    "        k_score = []\n",
    "        for i,j in combs:\n",
    "            if cooccurence[i,i] == 0 or cooccurence[j,j] == 0:\n",
    "                return (cooccurence, i, j)\n",
    "#                 continue\n",
    "                #print(np.where(clusters == idx_cluster))\n",
    "                #print(cooccurence[idx,:][:,idx])\n",
    "                raise RuntimeError(\"Some words do not occur in topic %d. Choose a smaller number of N.\" %\n",
    "                                   idx_cluster)\n",
    "            p_i = cooccurence[i,i]/total\n",
    "            p_j = cooccurence[j,j]/total\n",
    "            p_i_j = cooccurence[i,j]/total\n",
    "            score = np.log((p_i_j+0.001)/(p_i * p_j))/-np.log(p_i_j+0.001)\n",
    "            k_score.append(score)\n",
    "        k_topic = np.mean(np.asarray(k_score))\n",
    "        k_pmi.append(k_topic)\n",
    "    return k_pmi, np.mean(k_pmi), np.std(k_pmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 285)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_q_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_topic = best_q_matrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "c, i, j = calculate_uci_npmi_coherence_all_docs(test_data_features, word_topic, np.zeros((65,285)), 7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3332901816186372, 0.0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 285)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooc = np.dot(test_data_features.T, test_data_features)\n",
    "cooc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-055e9fd2b35a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "j[i,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = word_topic[:, 1].argsort()[::-1][:5]\n",
    "cooc[idx,:][:,idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot calculate UCI Coherence Top-15\n"
     ]
    }
   ],
   "source": [
    "npmi = []\n",
    "for n in [5,10,15]:\n",
    "    try:\n",
    "        npmi.append(calculate_uci_npmi_coherence_all_docs(test_data_features, word_topic, \n",
    "                                                          np.zeros((65,285)), 7, n)[1])\n",
    "    except RuntimeError:\n",
    "        print(\"Cannot calculate UCI Coherence Top-%d\" % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)\n",
    "plt.hist(y_pred)\n",
    "plt.hist(y_pred_binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als_tensor_factorization(student_performance, n_concepts=2, init=3, max_iter=100):\n",
    "    \n",
    "    # Get values from student performance tensor shape\n",
    "    n_students, n_questions, n_attempts = student_performance.shape\n",
    "    \n",
    "    # Create student knowledge tensor\n",
    "    student_knowledge = np.zeros((n_students, n_concepts, n_attempts))\n",
    "\n",
    "#     error_run = []\n",
    "#     error_total_run = []\n",
    "#     student_performance_pred_run = []\n",
    "    lambda1 = 0.1\n",
    "    lambda2 = 0.1\n",
    "    best_error = 9999\n",
    "    \n",
    "    # Several starts\n",
    "    for run in range(init):\n",
    "        print(\"Run: %d\" % run)\n",
    "        error = []\n",
    "        student_performance_pred_list = []\n",
    "    #     q_matrix = np.random.rand(N_QUESTIONS, N_CONCEPTS)\n",
    "\n",
    "        for attempt in range(n_attempts):\n",
    "            student_knowledge[:, :, attempt] = np.random.rand(n_students, n_concepts)\n",
    "\n",
    "        # Phase 1: prediction\n",
    "        student_performance_pred = np.zeros(student_performance.shape)\n",
    "        for i in range(max_iter):\n",
    "\n",
    "            # Update Q: Q = (T'T)^(-1)T'Y = T^(-1)Y\n",
    "            # (T'T)^(-1)\n",
    "            student_knowledge_transposed = np.zeros((n_concepts, n_concepts, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                student_knowledge_transposed[:, :, attempt] = np.dot(student_knowledge[:, :, attempt].T, \n",
    "                                                                     student_knowledge[:, :, attempt])\n",
    "            student_knowledge_transposed = student_knowledge_transposed.sum(axis=2)\n",
    "            student_knowledge_transposed_inv = np.linalg.pinv(student_knowledge_transposed)\n",
    "            \n",
    "            # T'Y\n",
    "            TY = np.zeros((n_concepts, n_questions, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                TY[:, :, attempt] = np.dot(student_knowledge[:, :, attempt].T, \n",
    "                                           student_performance[:, :, attempt])\n",
    "            TY = TY.sum(axis=2)\n",
    "            \n",
    "            ## TODO: add regularization parameters (lambda)\n",
    "            # Q = (T'T)^(-1)T'Y\n",
    "            q_matrix = np.dot(student_knowledge_transposed_inv, TY)\n",
    "            # Impose non-negativity constraint\n",
    "            q_matrix[q_matrix <= 0] = 0.0001\n",
    "            # Normalize rows to sum one\n",
    "            row_sums = q_matrix.sum(axis=0, keepdims=True)\n",
    "            if not (np.any(q_matrix.sum(axis=0))):\n",
    "                raise RuntimeError(\"Q Matrix with empty row\")\n",
    "            q_matrix = q_matrix / row_sums\n",
    "            \n",
    "            \n",
    "            # Update T: T = YQ'(QQ')^(-1) = YQ^(-1)\n",
    "            # (QQ')^(-1)\n",
    "#             try:\n",
    "            q_matrix_transpose_inv = np.linalg.pinv(np.dot(q_matrix, q_matrix.T))\n",
    "#             except np.linalg.LinAlgError:\n",
    "#                 continue\n",
    "            \n",
    "            # YQ'\n",
    "            YQ = np.zeros((n_students, n_concepts, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                YQ[:, :, attempt] = np.dot(student_performance[:, :, attempt], q_matrix.T)\n",
    "                \n",
    "            # T = YQ'(QQ')^(-1)\n",
    "            for attempt in range(n_attempts):\n",
    "                student_knowledge[:, :, attempt] = np.dot(YQ[:, :, attempt], q_matrix_transpose_inv)\n",
    "                \n",
    "            # Y = TQ\n",
    "            for attempt in range(n_attempts):\n",
    "                student_performance_pred[:, :, attempt] = np.dot(student_knowledge[:, :, attempt], q_matrix)\n",
    "                \n",
    "            \n",
    "            diff = np.zeros((n_students, n_questions, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                diff[:, :, attempt] = student_performance[:, :, attempt] - student_performance_pred[:, :, attempt]\n",
    "            # Frobenius norm (norm-2)\n",
    "            error = np.sqrt(np.sum(np.power(diff, 2)))\n",
    "#             error.append(np.sqrt(np.sum(np.power(diff, 2))))\n",
    "            if error < best_error:\n",
    "                best_student_performance_pred = student_performance_pred.copy()\n",
    "                best_student_knowledge = student_knowledge.copy()\n",
    "                best_q_matrix = q_matrix.copy()\n",
    "                best_error = error\n",
    "            \n",
    "#             student_performance_pred_iter = student_performance_pred.copy()\n",
    "#             student_performance_pred_list.append(student_performance_pred_iter)\n",
    "#         student_performance_pred_run.append(student_performance_pred_list)\n",
    "#         error_run.append(error)\n",
    "#         error_total_run.append(error[-1])\n",
    "    \n",
    "            \n",
    "#     return np.asarray(student_performance_pred_run), np.asarray(error_run), error_total_run\n",
    "    if best_error == 9999:\n",
    "        raise RuntimeError(\"Could not converge\")\n",
    "    return best_student_performance_pred, best_student_knowledge, best_q_matrix, best_error\n",
    "#     return (np.asarray(student_performance_pred_run), np.asarray(error_run), error_total_run, \n",
    "#             best_student_performance_pred, best_student_knowledge, best_q_matrix, best_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback_driven_tensor_factorization(student_performance, n_concepts=2, mu=0.1, init=3, max_iter=100):\n",
    "    \"\"\" Student performance: 0 if incorrect, 1 if correct or None if not observed \"\"\"\n",
    "    \n",
    "    # Get values from student performance tensor shape\n",
    "    n_students, n_questions, n_attempts = student_performance.shape\n",
    "    \n",
    "    # Construct tensor X denoting when a student has or has not chosen to work on a problem\n",
    "    X = np.ones(student_performance.shape)\n",
    "    X[np.where(np.isnan(student_performance))] = 0\n",
    "    # Complete student knowledge tensor with zero where is NaN\n",
    "    student_performance[np.where(np.isnan(student_performance))] = 0\n",
    "    \n",
    "    # Create student knowledge tensor\n",
    "    student_knowledge = np.zeros((n_students, n_concepts, n_attempts))\n",
    "\n",
    "#     error_run = []\n",
    "#     error_total_run = []\n",
    "#     student_performance_pred_run = []\n",
    "    best_error = 9999\n",
    "    lambda1 = 0.0001\n",
    "    \n",
    "    # Several starts\n",
    "    for run in range(init):\n",
    "        print(\"Run: %d\" % run)\n",
    "#         error = []\n",
    "        student_performance_pred_list = []\n",
    "\n",
    "#         for attempt in range(n_attempts):\n",
    "#             student_knowledge[:, :, attempt] = np.random.rand(n_students, n_concepts)\n",
    "        q_matrix = np.random.rand(n_concepts, n_questions)\n",
    "         # Impose non-negativity constraint\n",
    "        q_matrix[q_matrix <= 0] = 0.0001\n",
    "        # Normalize rows to sum one\n",
    "        row_sums = q_matrix.sum(axis=0, keepdims=True)\n",
    "        if not (np.any(q_matrix.sum(axis=0))):\n",
    "            raise RuntimeError(\"Q Matrix with empty row\")\n",
    "        q_matrix = q_matrix / row_sums\n",
    "\n",
    "        student_performance_pred = np.zeros(student_performance.shape)\n",
    "        for i in range(max_iter):\n",
    "            # Phase 2: learning\n",
    "            # Update T: T = 2*(T_{t-1}) + 2*((1-T_{t-1})/(1+exp(-mu*X_{t}*Q'))) - 1\n",
    "            # For T0 user T-1 as 0\n",
    "            student_knowledge[:, :, 0] = (2/(1+np.exp(-mu*np.dot(X[:,:,0], q_matrix.T))))-1\n",
    "            for attempt in range(1, n_attempts):\n",
    "                student_knowledge[:, :, attempt] = (2*student_knowledge[:, :, attempt-1]) + \\\n",
    "                2*(1-student_knowledge[:, :, attempt-1])/(1+np.exp(-mu*np.dot(X[:,:,attempt], q_matrix.T))) - 1\n",
    "                \n",
    "            # Phase 1: prediction\n",
    "            # Update Q: Q = (T'T)^(-1)T'Y = T^(-1)Y\n",
    "            # (T'T)^(-1)\n",
    "            student_knowledge_transposed = np.zeros((n_concepts, n_concepts, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                student_knowledge_transposed[:, :, attempt] = np.dot(student_knowledge[:, :, attempt].T, \n",
    "                                                                     student_knowledge[:, :, attempt])\n",
    "                \n",
    "            student_knowledge_transposed = student_knowledge_transposed.sum(axis=2)\n",
    "#             try:\n",
    "            student_knowledge_transposed_inv = np.linalg.pinv(student_knowledge_transposed+lambda1)\n",
    "#             except np.linalg.LinAlgError:\n",
    "#                 return student_knowledge, X, q_matrix, student_knowledge_transposed_inv, TY\n",
    "            \n",
    "            # T'Y\n",
    "            TY = np.zeros((n_concepts, n_questions, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                TY[:, :, attempt] = np.dot(student_knowledge[:, :, attempt].T, \n",
    "                                           student_performance[:, :, attempt])\n",
    "            TY = TY.sum(axis=2)\n",
    "            \n",
    "            ## TODO: add regularization parameters (lambda)\n",
    "            # Q = (T'T)^(-1)T'Y\n",
    "            q_matrix = np.dot(student_knowledge_transposed_inv, TY)\n",
    "            # Impose non-negativity constraint\n",
    "            q_matrix[q_matrix <= 0] = 0.0001\n",
    "            # Normalize rows to sum one\n",
    "            row_sums = q_matrix.sum(axis=0, keepdims=True)\n",
    "            if not (np.all(row_sums)):\n",
    "                raise RuntimeError(\"Q Matrix with empty row\")\n",
    "#                 print(\"Q Matrix with empty row\")\n",
    "#                 return q_matrix\n",
    "            q_matrix = q_matrix / row_sums\n",
    "            \n",
    "            # Y = TQ\n",
    "            for attempt in range(n_attempts):\n",
    "                student_performance_pred[:, :, attempt] = np.dot(student_knowledge[:, :, attempt], q_matrix)\n",
    "                \n",
    "            \n",
    "            diff = np.zeros((n_students, n_questions, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                diff[:, :, attempt] = student_performance[:, :, attempt] - student_performance_pred[:, :, attempt]\n",
    "            # Frobenius norm (norm-2)\n",
    "            error = np.sqrt(np.sum(np.power(diff, 2)))\n",
    "#             error.append(np.sqrt(np.sum(np.power(diff, 2))))\n",
    "            if error < best_error:\n",
    "                best_student_performance_pred = student_performance_pred.copy()\n",
    "                best_student_knowledge = student_knowledge.copy()\n",
    "                best_q_matrix = q_matrix.copy()\n",
    "                best_error = error\n",
    "            \n",
    "#             student_performance_pred_iter = student_performance_pred.copy()\n",
    "#             student_performance_pred_list.append(student_performance_pred_iter)\n",
    "#         student_performance_pred_run.append(student_performance_pred_list)\n",
    "#         error_run.append(error)\n",
    "#         error_total_run.append(error[-1])\n",
    "                \n",
    "#     return np.asarray(student_performance_pred_run), np.asarray(error_run), error_total_run\n",
    "    if best_error == 9999:\n",
    "        raise RuntimeError(\"Could not converge\")\n",
    "    return best_student_performance_pred, best_student_knowledge, best_q_matrix, best_error\n",
    "#     return (np.asarray(student_performance_pred_run), np.asarray(error_run), error_total_run, \n",
    "#             best_student_performance_pred, best_student_knowledge, best_q_matrix, best_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
