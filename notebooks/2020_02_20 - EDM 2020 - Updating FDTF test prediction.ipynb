{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# Helpers\n",
    "import numpy as np\n",
    "\n",
    "# DB \n",
    "import psycopg2\n",
    "from django.conf import settings\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import roc_curve, auc, f1_score\n",
    "from scipy import special\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(user = settings.DATABASES[\"default\"][\"USER\"],\n",
    "                                  password = settings.DATABASES[\"default\"][\"PASSWORD\"],\n",
    "                                  host = settings.DATABASES[\"default\"][\"HOST\"],\n",
    "                                  port = settings.DATABASES[\"default\"][\"PORT\"],\n",
    "                                  database = settings.DATABASES[\"default\"][\"NAME\"])\n",
    "connection.autocommit=True\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.41 s, sys: 6.03 s, total: 10.4 s\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"\"\"select experiment_id, dataset, sp_test, sp_hat, x, x_test, sk_hat, q_matrix_hat, mu\n",
    "from EDM2020_2020_06_05 where method='fdtf' and dataset <> 'run_all' \n",
    "and mu='0.1' and concepts >=11 and concepts <=16 and attempts_train = 150 order by experiment_id\"\"\"\n",
    "cursor.execute(query)\n",
    "row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2020_06_08_run_0\n",
      "Test: 453 \n",
      "Test all: 453\n",
      "Dataset 2020_06_08_run_0\n",
      "Test: 453 \n",
      "Test all: 453\n",
      "Dataset 2020_06_08_run_0\n",
      "Test: 453 \n",
      "Test all: 453\n",
      "Dataset 2020_06_08_run_0\n",
      "Test: 453 \n",
      "Test all: 453\n",
      "Dataset 2020_06_08_run_0\n",
      "Test: 453 \n",
      "Test all: 453\n",
      "Dataset 2020_06_08_run_1\n",
      "Test: 570 \n",
      "Test all: 570\n",
      "Dataset 2020_06_08_run_1\n",
      "Test: 570 \n",
      "Test all: 570\n",
      "Dataset 2020_06_08_run_1\n",
      "Test: 570 \n",
      "Test all: 570\n",
      "Dataset 2020_06_08_run_1\n",
      "Test: 570 \n",
      "Test all: 570\n",
      "Dataset 2020_06_08_run_1\n",
      "Test: 570 \n",
      "Test all: 570\n",
      "Dataset 2020_06_08_run_2\n",
      "Test: 476 \n",
      "Test all: 476\n",
      "Dataset 2020_06_08_run_2\n",
      "Test: 476 \n",
      "Test all: 476\n",
      "Dataset 2020_06_08_run_2\n",
      "Test: 476 \n",
      "Test all: 476\n",
      "Dataset 2020_06_08_run_2\n",
      "Test: 476 \n",
      "Test all: 476\n",
      "Dataset 2020_06_08_run_2\n",
      "Test: 476 \n",
      "Test all: 476\n",
      "Dataset 2020_06_08_run_3\n",
      "Test: 447 \n",
      "Test all: 447\n",
      "Dataset 2020_06_08_run_3\n",
      "Test: 447 \n",
      "Test all: 447\n",
      "Dataset 2020_06_08_run_3\n",
      "Test: 447 \n",
      "Test all: 447\n",
      "Dataset 2020_06_08_run_3\n",
      "Test: 447 \n",
      "Test all: 447\n",
      "Dataset 2020_06_08_run_3\n",
      "Test: 447 \n",
      "Test all: 447\n",
      "Dataset 2020_06_08_run_4\n",
      "Test: 473 \n",
      "Test all: 473\n",
      "Dataset 2020_06_08_run_4\n",
      "Test: 473 \n",
      "Test all: 473\n",
      "Dataset 2020_06_08_run_4\n",
      "Test: 473 \n",
      "Test all: 473\n",
      "Dataset 2020_06_08_run_4\n",
      "Test: 473 \n",
      "Test all: 473\n",
      "Dataset 2020_06_08_run_4\n",
      "Test: 473 \n",
      "Test all: 473\n",
      "Dataset 2020_06_08_run_5\n",
      "Test: 348 \n",
      "Test all: 348\n",
      "Dataset 2020_06_08_run_5\n",
      "Test: 348 \n",
      "Test all: 348\n",
      "Dataset 2020_06_08_run_5\n",
      "Test: 348 \n",
      "Test all: 348\n",
      "Dataset 2020_06_08_run_5\n",
      "Test: 348 \n",
      "Test all: 348\n",
      "Dataset 2020_06_08_run_5\n",
      "Test: 348 \n",
      "Test all: 348\n",
      "Dataset 2020_06_08_run_7\n",
      "Test: 422 \n",
      "Test all: 422\n",
      "Dataset 2020_06_08_run_7\n",
      "Test: 422 \n",
      "Test all: 422\n",
      "Dataset 2020_06_08_run_7\n",
      "Test: 422 \n",
      "Test all: 422\n",
      "Dataset 2020_06_08_run_7\n",
      "Test: 422 \n",
      "Test all: 422\n",
      "Dataset 2020_06_08_run_7\n",
      "Test: 422 \n",
      "Test all: 422\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "update_queries = []\n",
    "total = 0\n",
    "error_count = 0\n",
    "while row:\n",
    "    exp_id, dataset, sp_test, sp_hat, X, X_test, sk_hat, q_matrix_hat, mu = row\n",
    "    \n",
    "    X = np.asarray(X)\n",
    "    sp_test = np.asarray(sp_test)\n",
    "    sp_hat = np.asarray(sp_hat)\n",
    "    sk_hat = np.asarray(sk_hat)\n",
    "    X_test = np.asarray(X_test)\n",
    "    \n",
    "    #attempts_per_question = X.sum(axis=0).sum(axis=1)\n",
    "    #del_questions = [idx for idx,value in enumerate(attempts_per_question) if value < 3]\n",
    "    #total_questions = len(del_questions)\n",
    "\n",
    "    #if X_test.shape[1] != (48-total_questions):\n",
    "    #    X_test = np.delete(X_test, del_questions, axis=1)\n",
    "    #    sp_test = np.delete(sp_test, del_questions, axis=1)\n",
    "\n",
    "    sp_hat_test = np.zeros((sp_hat.shape[0], sp_hat.shape[1], sp_test.shape[2]))\n",
    "    attempts_begin = min(sp_test.shape[2], sp_hat.shape[2])\n",
    "    \n",
    "    ### CHOOSE ATTEMPT \n",
    "    # Not seen attempts\n",
    "    #attempts = X_test.shape[2]\n",
    "    # First 20 attempts\n",
    "    attempts = attempts_begin\n",
    "\n",
    "    sp_hat_test[:, :, :attempts_begin] = sp_hat[:, :, :attempts_begin]\n",
    "    sk_hat_test = np.zeros((sk_hat.shape[0], sk_hat.shape[1], sp_test.shape[2]))\n",
    "    sk_hat_test[:, :, :attempts_begin] = sk_hat[:, :, :attempts_begin]\n",
    "    q_matrix_hat = np.asarray(q_matrix_hat)\n",
    "    \n",
    "    # Calculate SK and SP for the next test attempts\n",
    "    for attempt in range(1, attempts):\n",
    "        students = np.where(X_test[:,:, attempt] == 1)[0]\n",
    "#         print(\"%d students in attempt %d\" % (len(students), attempt))\n",
    "        for student in students:\n",
    "            sk_hat_test[student, :, attempt] = (2*sk_hat_test[student, :, attempt-1]) + \\\n",
    "                                            2*(1-sk_hat_test[student, :, attempt-1])/(1+np.exp(\n",
    "                                                -mu*np.dot(X_test[student, :, attempt], q_matrix_hat.T))) - 1\n",
    "            sp_hat_test[student, :, attempt] = np.dot(sk_hat_test[student, :, attempt], q_matrix_hat)\n",
    "    \n",
    "    # Get test predicted values\n",
    "    y = sp_test[np.where(X_test[:,:,:attempt+1] == 1)]\n",
    "    y_pred = sp_hat_test[np.where(X_test[:,:,:attempt+1] == 1)]\n",
    "    \n",
    "    # Calculate AUC\n",
    "    #fpr, tpr, thresholds = roc_curve(y, y_pred, pos_label=1)\n",
    "    #auc_score = auc(fpr, tpr)\n",
    "    #J_stats = tpr - fpr\n",
    "    \n",
    "    # Binarize prediction\n",
    "    #y_pred_binary = np.where(np.asarray(y_pred) > auc_threshold, 1, 0)\n",
    "    \n",
    "    # Calculate accuracy, RMSE, NLL\n",
    "    #acc = np.logical_not(np.logical_xor(y, y_pred_binary)).sum()/len(y)\n",
    "    rmse = np.sqrt(np.mean(np.power(y - y_pred, 2)))\n",
    "    #y_1 = y[np.where(y == 1)]\n",
    "    #y_pred_1 = y_pred[np.where(y == 1)]\n",
    "    #y_0 = y[np.where(y == 0)]\n",
    "    #y_pred_0 = y_pred[np.where(y == 0)]\n",
    "    #rmse_1 = np.sqrt(np.mean(np.power(y_1 - y_pred_1, 2))) \n",
    "    #rmse_0 = np.sqrt(np.mean(np.power(y_0 - y_pred_0, 2))) \n",
    "    #f1 = f1_score(y, y_pred_binary)\n",
    "    #nll = -special.xlogy(y, y_pred) - special.xlogy(1-y, 1-y_pred)\n",
    "    \n",
    "\n",
    "    #y_pred_all = np.zeros((y.shape[0], 2))\n",
    "    #y_pred_all[:,0] = 1-y_pred\n",
    "    #y_pred_all[:,1] = y_pred\n",
    "    #nll_special = (-np.ma.log(y_pred_all[range(y.shape[0]),y.astype(int)])).mean()\n",
    "\n",
    "    # Substitute inf by max NLL\n",
    "    #idx = np.where(np.isinf(nll))\n",
    "    #nll[idx] = 0\n",
    "    #max_nll = np.max(nll)\n",
    "    #nll[idx] = max_nll\n",
    "    #nll = np.mean(nll)\n",
    "    \n",
    "    update = {\n",
    "#         \"test_acc\": acc,\n",
    "#         \"test_rmse\": rmse,\n",
    "        \"test_rmse_att\": rmse,\n",
    "#         \"test_rmse_all\": rmse,\n",
    "#         \"max_test_att\": attempts\n",
    "#         \"test_1\":  np.where(y == 1)[0].shape[0],\n",
    "#         \"test_0\":  np.where(y == 0)[0].shape[0],\n",
    "#         \"test_pred_1\": np.where(y_pred_binary == 1)[0].shape[0],\n",
    "#         \"test_pred_0\": np.where(y_pred_binary == 0)[0].shape[0],\n",
    "#         \"test_f1\": f1,\n",
    "#         \"test_nll\": nll,\n",
    "#         \"test_nll_special\": nll_special,\n",
    "#         \"test_nll_masked\": idx[0].shape[0],\n",
    "#         \"test_rmse_1\": rmse_1,\n",
    "#         \"test_rmse_0\": rmse_0\n",
    "    }\n",
    "    \n",
    "#     # Write PSQL query\n",
    "    update_query = \"UPDATE EDM2020_2020_06_05 SET \"\n",
    "    update_list = []\n",
    "    query_values = []\n",
    "    for key, value in update.items():\n",
    "        update_list.append(key + \"= %s\")\n",
    "        query_values.append(value)\n",
    "    \n",
    "    update_query += \", \".join(update_list) + \"where experiment_id = %s\"\n",
    "    query_values.append(exp_id)\n",
    "    query_values = tuple(query_values)\n",
    "    query = cursor.mogrify(update_query, query_values)\n",
    "    update_queries.append(query)\n",
    "    total += 1\n",
    "    \n",
    "    print(\"Dataset %s\" % dataset)\n",
    "    print(\"Test: %d \" % y.shape[0])\n",
    "    print(\"Test all: %d\" % np.where(X_test == 1)[0].shape[0])\n",
    "    \n",
    "    try:\n",
    "        row = cursor.fetchone()\n",
    "    except psycopg2.ProgrammingError:\n",
    "        row = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 4.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for query in update_queries:\n",
    "    cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
