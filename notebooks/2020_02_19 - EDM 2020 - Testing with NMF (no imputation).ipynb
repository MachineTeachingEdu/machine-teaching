{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "# DB \n",
    "import psycopg2\n",
    "from django.conf import settings\n",
    "\n",
    "# Learning\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import roc_curve, auc, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(user = settings.DATABASES[\"default\"][\"USER\"],\n",
    "                                  password = settings.DATABASES[\"default\"][\"PASSWORD\"],\n",
    "                                  host = settings.DATABASES[\"default\"][\"HOST\"],\n",
    "                                  port = settings.DATABASES[\"default\"][\"PORT\"],\n",
    "                                  database = settings.DATABASES[\"default\"][\"NAME\"])\n",
    "connection.autocommit=True\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data/edm2020\"\n",
    "N_RUNS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_matrix(data, tensor, X, attempt_agg='avg', filter_attempt=False):\n",
    "    attempts_count = defaultdict(int)\n",
    "    for item in data:\n",
    "        s_idx, q_idx, a_idx, outcome = item\n",
    "        \n",
    "        # If attempt filter is provided\n",
    "        if filter_attempt and attempts_count[(s_idx, q_idx)] >= filter_attempt:\n",
    "            continue\n",
    "        else:\n",
    "            attempts_count[(s_idx, q_idx)] += 1\n",
    "        \n",
    "        tensor[s_idx, q_idx, a_idx] = outcome\n",
    "        X[s_idx, q_idx, a_idx] = 1\n",
    "    tensor[np.where(X[:,:] == 0)] = None\n",
    "\n",
    "    # # Average over all attempts for one question\n",
    "    if attempt_agg == 'avg':\n",
    "        # Used to ignore NaN warnings\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            matrix = np.nanmean(tensor, axis=2)\n",
    "            # 0.1 means the student at least tried opposing to 0, which is the he/she did not attempt the question\n",
    "#             matrix[np.where(matrix < 0.1)] = 0\n",
    "#         matrix[np.where(np.isnan(matrix) == True)] = None\n",
    "\n",
    "    return matrix, X\n",
    "    \n",
    "def transform_data(data, n_attempts):\n",
    "    N_STUDENTS = len(data['users_idx'])\n",
    "    N_QUESTIONS = len(data['questions_idx'])\n",
    "    \n",
    "    max_attempt = np.max(data['train_set'][:,2])+1\n",
    "    student_performance_tensor = np.zeros((N_STUDENTS, N_QUESTIONS, max_attempt))\n",
    "    X = np.zeros(student_performance_tensor.shape)\n",
    "\n",
    "    student_performance, X = add_to_matrix(data['train_set'], \n",
    "                                        student_performance_tensor, \n",
    "                                        X, filter_attempt=n_attempts)\n",
    "    \n",
    "    max_attempt = np.max(data['test_set'][:,2])+1\n",
    "    student_performance_test_tensor = np.zeros((N_STUDENTS, N_QUESTIONS, max_attempt))\n",
    "    X_test = np.zeros(student_performance_test_tensor.shape)\n",
    "    student_performance_test, X_test = add_to_matrix(data['test_set'], \n",
    "                                             student_performance_test_tensor, \n",
    "                                             X_test, filter_attempt=n_attempts)\n",
    "    return student_performance, X, student_performance_test, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do grid search to explore parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "n_concepts = range(18, 23)\n",
    "# attempts = [False, 1, 3]\n",
    "attempts = [1]\n",
    "# l1_ratio = [0, 0.3, 0.5, 0.7, 1]\n",
    "l1_ratio = [0, 0.3, 0.5]\n",
    "# alpha = list(np.arange(0, 1, 0.1)) + list(range(1, 10, 1))\n",
    "alpha = list(np.arange(0, 0.3, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = 1 * N_RUNS * len(attempts) * len(n_concepts) * len(l1_ratio) * len(alpha)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010416666666666667"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = (0.4*search)/(60*60*24)\n",
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(*args):\n",
    "    (dataset, data, att, student_performance, X, student_performance_test, X_test,\n",
    "     del_questions, concept, alpha, l1_ratio) = args\n",
    "    \n",
    "    # Run NMF\n",
    "    start = time.time()\n",
    "    (best_student_performance_pred, best_student_knowledge, \n",
    "     best_q_matrix, best_error) = non_negative_matrix_factorization(\n",
    "        student_performance, concept, alpha, l1_ratio, init=10, max_iter=1000)\n",
    "#     a = non_negative_matrix_factorization(student_performance, concept, alpha, l1_ratio, init=10, max_iter=1000)\n",
    "#     return a\n",
    "    end = time.time()\n",
    "\n",
    "    # Delete questions from original q_matrix\n",
    "    q_matrix = np.delete(data['q_matrix'], del_questions, axis=1)\n",
    "    question_similarity = cosine_similarity(q_matrix.T)\n",
    "    question_hat_similarity = cosine_similarity(np.asarray(best_q_matrix).T)\n",
    "    error = question_similarity - question_hat_similarity\n",
    "    q_matrix_error = np.sqrt(np.sum(np.power(error,2)))\n",
    "    q_matrix_rmse = np.sqrt(np.mean(np.power(error,2)))\n",
    "    \n",
    "    # Get train predicted values\n",
    "    y = student_performance[np.where(np.isnan(student_performance) == False)]\n",
    "    y_pred = best_student_performance_pred[np.where(np.isnan(student_performance) == False)]\n",
    "    rmse = np.sqrt(np.mean(np.power(y - y_pred, 2))) \n",
    "\n",
    "    row = {\n",
    "        \"dataset\": \"run_%d\" % dataset,\n",
    "        \"q_matrix\": q_matrix,\n",
    "#                         \"X\": X,\n",
    "        \"sp\": student_performance,\n",
    "# #                         \"X_test\": X_test,\n",
    "        \"sp_test\": student_performance_test,\n",
    "        \"sp_hat\": best_student_performance_pred,\n",
    "        \"sk_hat\": best_student_knowledge,\n",
    "        \"q_matrix_hat\": best_q_matrix,\n",
    "#                         \"mu\": m,\n",
    "        \"concepts\": concept,\n",
    "        \"attempts_train\": int(att),\n",
    "        \"method\": \"nmf_no_imput\",\n",
    "        \"q_matrix_error\": q_matrix_error,\n",
    "        \"q_matrix_rmse\": q_matrix_rmse,\n",
    "        \"reconstruction_error\": best_error,\n",
    "        \"train_error\": 0,\n",
    "        \"test_error\": 0,\n",
    "        \"seconds\": end-start,\n",
    "        \"train_rmse\": rmse,\n",
    "        \"alpha\": alpha,\n",
    "        \"l1_ratio\": l1_ratio\n",
    "    }\n",
    "    \n",
    "     # If just first attempt, we can binarize predictions\n",
    "    if att == 1:\n",
    "        # Calculate AUC and threshold to binarize prediction\n",
    "        fpr, tpr, thresholds = roc_curve(y, y_pred, pos_label=1)\n",
    "        auc_score = auc(fpr, tpr)\n",
    "        J_stats = tpr - fpr\n",
    "        J_opt_thresholds = thresholds[np.argmax(J_stats)]\n",
    "        y_pred_binary = np.where(np.asarray(y_pred) > J_opt_thresholds, 1, 0)\n",
    "    \n",
    "         # Calculate accuracy and F1\n",
    "        acc = np.logical_not(np.logical_xor(y, y_pred_binary)).sum()/len(y)\n",
    "        f1 = f1_score(y, y_pred_binary)\n",
    "        \n",
    "        row.update({\n",
    "            \"train_auc\": auc_score,\n",
    "            \"train_acc\": acc,\n",
    "            \"auc_threshold\": J_opt_thresholds,\n",
    "            \"train_1\":  np.where(y == 1)[0].shape[0],\n",
    "            \"train_0\":  np.where(y == 0)[0].shape[0],\n",
    "            \"train_pred_1\": np.where(y_pred_binary == 1)[0].shape[0],\n",
    "            \"train_pred_0\": np.where(y_pred_binary == 0)[0].shape[0],\n",
    "            \"train_f1\": f1\n",
    "        })\n",
    "\n",
    "    # Write PSQL query\n",
    "    insert_query_base = \"INSERT INTO EDM2020_2020_02_19 \"\n",
    "    column_value = []\n",
    "    insert_format = []\n",
    "    query_values = []\n",
    "    for col in row.keys():\n",
    "        if isinstance(row[col], np.ndarray):\n",
    "            query_values.append(row[col].tolist())\n",
    "        else:\n",
    "            query_values.append(row[col])\n",
    "        column_value.append(col)\n",
    "        insert_format.append(\"%s\")\n",
    "\n",
    "    insert_query = insert_query_base + \"(\" + \", \".join(column_value) + \") VALUES \"\n",
    "    insert_query += \"(\" + \", \".join(insert_format) + \")\"\n",
    "    query_values = tuple(query_values)\n",
    "    query = cursor.mogrify(insert_query, query_values)\n",
    "    cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = []\n",
    "\n",
    "for restart in range(1):\n",
    "    for dataset in range(N_RUNS):\n",
    "        with open(\"%s/run_%d.pkl\" % (folder, dataset), \"rb\") as pklfile:\n",
    "            data = pickle.load(pklfile)\n",
    "        for att in attempts:\n",
    "            # Get train and test data in FDTF format\n",
    "            student_performance, X, student_performance_test, X_test = transform_data(data, att)\n",
    "            \n",
    "            # Check if questions have minimum number of attempts\n",
    "            attempts_per_question = student_performance.sum(axis=0)           \n",
    "            del_questions = [idx for idx,value in enumerate(attempts_per_question) if value == 0]\n",
    "#             print(del_questions)\n",
    "            student_performance = np.delete(student_performance, del_questions, axis=1)\n",
    "            \n",
    "            for l in l1_ratio:\n",
    "                for a in alpha:\n",
    "                    for concept in n_concepts:         \n",
    "                        args.append([dataset, \n",
    "                                     data, \n",
    "                                     att, \n",
    "                                     student_performance,\n",
    "                                     X,\n",
    "                                     student_performance_test, \n",
    "                                     X_test,\n",
    "                                     del_questions, \n",
    "                                     concept, \n",
    "                                     a, \n",
    "                                     l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset, data, att, student_performance, X, student_performance_test, X_test,\n",
    "     del_questions, concept_a, alpha_a, l1_ratio_a) = args[N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0, 21)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_a, l1_ratio_a, concept_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_id = N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "too many iterations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-412-e743ae470337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-320-c83e6666114f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m      7\u001b[0m     (best_student_performance_pred, best_student_knowledge, \n\u001b[1;32m      8\u001b[0m      \u001b[0mbest_q_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_error\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_negative_matrix_factorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         student_performance, concept, alpha, l1_ratio, init=10, max_iter=1000)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#     a = non_negative_matrix_factorization(student_performance, concept, alpha, l1_ratio, init=10, max_iter=1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#     return a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-405-ca20d17879ab>\u001b[0m in \u001b[0;36mnon_negative_matrix_factorization\u001b[0;34m(student_performance, concept, alpha, l1_ratio, init, max_iter)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#         model = NMF(n_components=concept, init='random', solver='cd',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#                     alpha=alpha, l1_ratio=l1_ratio, max_iter=max_iter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mstudent_knowledge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_nmf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_performance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;31m#         a = run_nmf(student_performance, concept, alpha, l1_ratio)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#         return a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-405-ca20d17879ab>\u001b[0m in \u001b[0;36mrun_nmf\u001b[0;34m(student_performance, concept, alpha, l1_ratio, init, max_iter)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mmask_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_performance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_rows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_rows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mWH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/machine_teaching/lib/python3.6/site-packages/scipy/optimize/nnls.py\u001b[0m in \u001b[0;36mnnls\u001b[0;34m(A, b, maxiter)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nnls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"too many iterations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: too many iterations"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "connection = psycopg2.connect(user = settings.DATABASES[\"default\"][\"USER\"],\n",
    "                                  password = settings.DATABASES[\"default\"][\"PASSWORD\"],\n",
    "                                  host = settings.DATABASES[\"default\"][\"HOST\"],\n",
    "                                  port = settings.DATABASES[\"default\"][\"PORT\"],\n",
    "                                  database = settings.DATABASES[\"default\"][\"NAME\"])\n",
    "connection.autocommit=True\n",
    "cursor = connection.cursor()\n",
    "\n",
    "for item in args[next_id:]:\n",
    "    run(*item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import nnls\n",
    "\n",
    "def cost(A, W, H):\n",
    "    from numpy import linalg\n",
    "    mask = np.logical_not(np.isnan(A))\n",
    "    WH = np.dot(W, H)\n",
    "    WH_mask = WH[mask]\n",
    "    A_mask = A[mask]\n",
    "    A_WH_mask = A_mask-WH_mask\n",
    "    # Since now A_WH_mask is a vector, we use L2 instead of Frobenius norm for matrix\n",
    "    return linalg.norm(A_WH_mask, 2)\n",
    "#     return A_WH_mask\n",
    "\n",
    "def run_nmf(student_performance, concept, alpha, l1_ratio, init=10, max_iter=200):\n",
    "    best_error = 9999\n",
    "    A = student_performance.copy()\n",
    "    K = concept\n",
    "    W = np.abs(np.random.uniform(low=0, high=1, size=(A.shape[0], K)))\n",
    "    H = np.abs(np.random.uniform(low=0, high=1, size=(K, A.shape[1])))\n",
    "    W = np.divide(W, K*W.max())\n",
    "    H = np.divide(H, K*H.max())\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        if i%2 == 0:\n",
    "            # Learn H, given A and W\n",
    "            for j in range(A.shape[1]):\n",
    "                mask_rows = np.logical_not(np.isnan(student_performance[:,j]))\n",
    "                H[:,j] = nnls(W[mask_rows], A[:,j][mask_rows], maxiter=150000)[0]\n",
    "        else:\n",
    "            for j in range(A.shape[0]):\n",
    "                mask_rows = np.logical_not(np.isnan(student_performance[j,:]))\n",
    "                W[j,:] = nnls(H.transpose()[mask_rows], A[j,:][mask_rows])[0]\n",
    "        WH = np.dot(W, H)\n",
    "        c = cost(A, W, H)\n",
    "#         return c\n",
    "    return W, H, c\n",
    "\n",
    "# def run_nmf(model, student_performance, concept, alpha, l1_ratio):\n",
    "#     student_knowledge = model.fit_transform(student_performance)\n",
    "#     q_matrix = model.components_\n",
    "#     error = model.reconstruction_err_\n",
    "    \n",
    "#     return student_knowledge, q_matrix, error\n",
    "    \n",
    "def non_negative_matrix_factorization(student_performance, concept, alpha, l1_ratio, init=10, max_iter=200):\n",
    "    \n",
    "    best_error = 9999\n",
    "    \n",
    "#     # First init use nndsvd\n",
    "#     model = NMF(n_components=concept, init='nndsvd', solver='mu', alpha=alpha, \n",
    "#                 l1_ratio=l1_ratio, max_iter=max_iter)\n",
    "#     student_knowledge, q_matrix, error = run_nmf(model, student_performance, concept, alpha, l1_ratio)\n",
    "    \n",
    "#     if error < best_error:\n",
    "#         best_student_knowledge = student_knowledge\n",
    "#         best_q_matrix = q_matrix\n",
    "#         best_error = error\n",
    "    \n",
    "    # Generate some random inits as well\n",
    "    for i in range(2, init):\n",
    "#         model = NMF(n_components=concept, init='random', solver='cd', \n",
    "#                     alpha=alpha, l1_ratio=l1_ratio, max_iter=max_iter)\n",
    "        student_knowledge, q_matrix, error = run_nmf(student_performance, concept, alpha, l1_ratio)\n",
    "#         a = run_nmf(student_performance, concept, alpha, l1_ratio)\n",
    "#         return a\n",
    "        \n",
    "        if error < best_error:\n",
    "            best_student_knowledge = student_knowledge\n",
    "            best_q_matrix = q_matrix\n",
    "            best_error = error\n",
    "    best_student_performance_pred = np.dot(best_student_knowledge, best_q_matrix)\n",
    "            \n",
    "    return (best_student_performance_pred, best_student_knowledge, best_q_matrix, best_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
