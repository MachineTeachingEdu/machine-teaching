{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pickle\n",
    "import qgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"clustering_bcc.pkl\", \"rb\") as pklfile:\n",
    "    df = pickle.load(pklfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0097396b2e349cdb0801f2b64fb4ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defauâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qgrid.show_grid(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(user = \"machineteaching\",\n",
    "                                  password = \"***REMOVED***\",\n",
    "                                  host = \"localhost\",\n",
    "#                                   port = \"5432\",\n",
    "                                  database = \"machineteaching\")\n",
    "connection.autocommit=True\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query = '''CREATE TABLE EXPERIMENTS\n",
    "    (EXPERIMENT_ID SERIAL PRIMARY KEY,\n",
    "    DATASET TEXT NOT NULL,\n",
    "    X REAL ARRAY NOT NULL,\n",
    "    Y REAL ARRAY NOT NULL,\n",
    "    VECTORIZER TEXT NOT NULL,\n",
    "    IS_BINARY BOOLEAN NOT NULL,\n",
    "    MIN_DF REAL NOT NULL,\n",
    "    DISTANCE TEXT NOT NULL,\n",
    "    K INTEGER NOT NULL,\n",
    "    METHOD TEXT NOT NULL,\n",
    "    MODEL TEXT NOT NULL,\n",
    "    GAP REAL NOT NULL,\n",
    "    GAP_STD REAL NOT NULL,\n",
    "    GAP_TIME REAL NOT NULL,\n",
    "    SILHOUETTE REAL NOT NULL,\n",
    "    SILHOUETTE_SAMPLES REAL ARRAY NOT NULL,\n",
    "    SILHOUETTE_TIME REAL NOT NULL,\n",
    "    COHERENCE_SAMPLES REAL ARRAY NOT NULL,\n",
    "    COHERENCE_MED REAL NOT NULL,\n",
    "    COHERENCE_STD REAL NOT NULL,\n",
    "    COHERENCE_TIME REAL NOT NULL,\n",
    "    COHERENCE_K INTEGER NOT NULL)\n",
    "    '''\n",
    "\n",
    "cursor.execute(create_table_query)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_table = \"\"\"INSERT INTO EXPERIMENTS  (\n",
    "    DATASET,\n",
    "    X,\n",
    "    Y,\n",
    "    VECTORIZER,\n",
    "    IS_BINARY,\n",
    "    MIN_DF,\n",
    "    DISTANCE,\n",
    "    K,\n",
    "    METHOD,\n",
    "    MODEL,\n",
    "    GAP,\n",
    "    GAP_STD,\n",
    "    GAP_TIME,\n",
    "    SILHOUETTE,\n",
    "    SILHOUETTE_SAMPLES,\n",
    "    SILHOUETTE_TIME,\n",
    "    COHERENCE_SAMPLES,\n",
    "    COHERENCE_MED,\n",
    "    COHERENCE_STD,\n",
    "    COHERENCE_TIME,\n",
    "    COHERENCE_K) \n",
    "    VALUES (\n",
    "        %s,\n",
    "        )\n",
    "\"\"\" % insert_query\n",
    "\n",
    "# d = cursor.mogrify(insert_table)\n",
    "# print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(df.shape[0]):\n",
    "    values = []\n",
    "    for col in df.columns:\n",
    "        values.append(\"%s\" % (df[col].values.tolist()[idx]))\n",
    "    break\n",
    "t = \", \".join(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'SELECT ARRAY[ARRAY[10,20,30],ARRAY[1,2,3]];'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.mogrify(\"SELECT %s;\", ([[10, 20, 30],[1,2,3]], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.iterrows():\n",
    "    query = []\n",
    "    for col in df.columns:\n",
    "        if isinstance(row[1][col], np.ndarray):\n",
    "            value = cursor.mogrify(\"%s\", (row[1][col].tolist(),))\n",
    "        else:\n",
    "            value = value\n",
    "        query.append(value)\n",
    "    break\n",
    "insert_query = b\", \".join(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'SELECT ARRAY[ARRAY[1,2,3],ARRAY[10,20,30]];'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.mogrify(\"SELECT %s;\", ([[1,2,3],[10, 20, 30]], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "insert_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "syntax error at or near \")\"\nLINE 25:         )\n                 ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-d68b336a825f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m: syntax error at or near \")\"\nLINE 25:         )\n                 ^\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(insert_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'INSERT INTO EXPERIMENTS (X) VALUES ([[1 0 1 ... 0 0 0]\\n [0 1 0 ... 1 0 0]\\n [1 0 0 ... 1 1 0]\\n ...\\n [0 0 0 ... 1 0 0]\\n [0 0 0 ... 0 1 1]\\n [1 0 0 ... 1 1 1]])'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.mogrify(\"\"\"INSERT INTO EXPERIMENTS (X) VALUES (%s)\"\"\" % df['X'].values.tolist()[0])\n",
    "# df['X'].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, numpy.ndarray found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f1064fbe599a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, numpy.ndarray found"
     ]
    }
   ],
   "source": [
    "df.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psycopg2\n",
    "engine = create_engine('postgresql+psycopg2://machineteaching:***REMOVED***@localhost/machineteaching')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The type of X is not a SQLAlchemy type ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-97532a1daab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'experiments'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'append'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"ARRAY\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/machine_teaching/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         sql.to_sql(self, name, con, flavor=flavor, schema=schema,\n\u001b[1;32m   1533\u001b[0m                    \u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m                    chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[1;32m   1535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m     def to_pickle(self, path, compression='infer',\n",
      "\u001b[0;32m~/miniconda3/envs/machine_teaching/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[1;32m    471\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[1;32m    472\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                       chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/machine_teaching/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeEngine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                     raise ValueError('The type of %s is not a SQLAlchemy '\n\u001b[0;32m-> 1150\u001b[0;31m                                      'type ' % col)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         table = SQLTable(name, self, frame=frame, index=index,\n",
      "\u001b[0;31mValueError\u001b[0m: The type of X is not a SQLAlchemy type "
     ]
    }
   ],
   "source": [
    "df.to_sql('experiments', con=engine, if_exists='append', dtype={\"X\": \"ARRAY\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
