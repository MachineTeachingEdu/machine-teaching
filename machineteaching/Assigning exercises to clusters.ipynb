{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 26\n",
    "\n",
    "- Min DF: 0.05\n",
    "- Binary: True\n",
    "- Vectorizer: Count\n",
    "- Method: LDA\n",
    "- Best k: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "# from db import PythonProblems\n",
    "import io\n",
    "\n",
    "# DB\n",
    "from questions.models import Solution, Cluster\n",
    "import psycopg2\n",
    "\n",
    "# Helpers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import base64\n",
    "\n",
    "# Preprocessing\n",
    "from tokenizer import create_bag_of_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Learning\n",
    "from clustering import Clustering\n",
    "from analyzer import python_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problems to be ignored: 597\n",
      "Problems to be used: 132\n",
      "Solutions to be used: 54\n",
      "Got 54 documents\n"
     ]
    }
   ],
   "source": [
    "## Cleaning database\n",
    "last_id = 132\n",
    "problems = Problem.objects.filter(id__gt=last_id)\n",
    "solutions_obj = Solution.objects.filter(problem__in=problems).update(ignore=True)\n",
    "print(\"Problems to be ignored: %d\" % problems.count())\n",
    "\n",
    "problems = Problem.objects.filter(id__lte=last_id)\n",
    "# problems = Problem.objects.all()\n",
    "print(\"Problems to be used: %d\" % problems.count())\n",
    "\n",
    "solutions_obj = Solution.objects.filter(problem__in=problems, ignore=False).order_by('id')\n",
    "# solutions_obj = Solution.objects.all().order_by('id')\n",
    "print(\"Solutions to be used: %d\" % solutions_obj.count())\n",
    "\n",
    "docs_id = []\n",
    "questions = []\n",
    "solutions = []\n",
    "\n",
    "# Fill separated structures\n",
    "for sol in solutions_obj:\n",
    "    docs_id.append(sol.id)\n",
    "    questions.append(sol.problem.content)\n",
    "    solutions.append(sol.content)\n",
    "\n",
    "print(\"Got %d documents\" %(solutions_obj.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(user = \"machineteaching\",\n",
    "                                  password = \"***REMOVED***\",\n",
    "                                  host = \"localhost\",\n",
    "#                                   port = \"5432\",\n",
    "                                  database = \"machineteaching\")\n",
    "connection.autocommit=True\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_where_items(exp_id):\n",
    "    cols = [\"vectorizer\", \"min_df\", \"is_binary\", \"distance\", \"method\", \"dataset\", \"k\", \"model\", \"X\"]\n",
    "    query = \"SELECT %s from experiments_solution where experiment_id = %s\" % (\", \".join(cols), exp_id) \n",
    "    cursor.execute(query)\n",
    "    where_items = cursor.fetchall()\n",
    "    return where_items\n",
    "\n",
    "def analyze(solutions, where_items, exp_id):\n",
    "    v = eval(where_items[0][0])\n",
    "    m = where_items[0][1]\n",
    "    b = where_items[0][2]\n",
    "    dist = where_items[0][3]\n",
    "    method = where_items[0][4]\n",
    "    k = where_items[0][6]\n",
    "    model_db = pickle.loads(base64.b64decode(where_items[0][7]))\n",
    "    X = np.asarray(where_items[0][8])\n",
    "\n",
    "    train_data_features, vectorizer, feature_names = create_bag_of_words(solutions, v, binary=b, min_df=m)\n",
    "    clustering = Clustering(train_data_features, k, metric=dist)\n",
    "    clustering.seed = model_db.random_state\n",
    "    \n",
    "    model, document_topic, word_topic = getattr(clustering, method)()\n",
    "    \n",
    "    return document_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditions\n",
      "('CountVectorizer', 0.05, True, 'euclidean', 'lda', 'solution_all', 12)\n"
     ]
    }
   ],
   "source": [
    "# Get experiment conditions\n",
    "exp_id = 26\n",
    "where_items = get_where_items(exp_id)\n",
    "print(\"Conditions\")\n",
    "print(where_items[0][0:7])\n",
    "\n",
    "document_topic = analyze(solutions, where_items, exp_id)\n",
    "document_clusters = document_topic.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters_def = {\n",
    "    4: \"String manipulation\",\n",
    "    6: \"Math functions\",\n",
    "    8: \"Conditional structure\",\n",
    "    10: \"List loops\",\n",
    "    12: \"Math and string loops\"\n",
    "}\n",
    "\n",
    "for key,value in clusters_def.items():\n",
    "    cluster = Cluster(id=key, label=value)\n",
    "    cluster.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign solutions to clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear all clusters\n",
    "for item in Solution.objects.filter(cluster__isnull=False):\n",
    "    item.cluster=None\n",
    "    item.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution 770 from cluster 1 was not assigned\n",
      "Assigning to 2nd best: 6\n",
      "Solution 772 from cluster 7 was not assigned\n",
      "Assigning to 2nd best: 8\n",
      "Solution 786 from cluster 1 was not assigned\n",
      "Assigning to 2nd best: 6\n",
      "Solution 806 from cluster 5 was not assigned\n",
      "Assigning to 2nd best: 6\n",
      "Solution 808 from cluster 3 was not assigned\n",
      "Assigning to 2nd best: 6\n"
     ]
    }
   ],
   "source": [
    "clusters_merge = {\n",
    "    2: 4\n",
    "}\n",
    "\n",
    "for idx, doc_id in enumerate(docs_id):\n",
    "    # Assigning docs to valid clusters\n",
    "    if (document_clusters[idx]+1) in clusters_def.keys():\n",
    "        solution = Solution.objects.get(pk=doc_id)\n",
    "        cluster = Cluster.objects.get(pk=(document_clusters[idx]+1))\n",
    "        solution.cluster=cluster\n",
    "#         solution.save()\n",
    "    elif (document_clusters[idx]+1) in clusters_merge.keys():\n",
    "        solution = Solution.objects.get(pk=doc_id)\n",
    "        cluster = Cluster.objects.get(pk=(clusters_merge[document_clusters[idx]+1]))\n",
    "        solution.cluster=cluster\n",
    "#         solution.save()\n",
    "    # Assign 2nd best value\n",
    "    else:\n",
    "        print(\"Solution %d from cluster %d was not assigned\" % (doc_id, document_clusters[idx]+1))\n",
    "        solution = Solution.objects.get(pk=doc_id)\n",
    "        max_idx = np.argsort(document_topic[idx])[::-1]\n",
    "        cluster = Cluster.objects.get(pk=(max_idx[1]+1))\n",
    "        print(\"Assigning to 2nd best: %d\" % cluster.pk)\n",
    "        solution.cluster=cluster\n",
    "        solution.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning new solutions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0026042  0.00260418 0.00260422 0.00260418 0.00260418 0.00260424\n",
      "  0.00260427 0.97135381 0.00260417 0.00260421 0.00260417 0.00260419]]\n",
      "8\n",
      "7\n",
      "6\n",
      "3\n",
      "10\n",
      "1\n",
      "12\n",
      "4\n",
      "2\n",
      "5\n",
      "11\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "def assign_to_cluster(exp_id, solutions, exercise_sol):\n",
    "    where_items = get_where_items(exp_id)\n",
    "    v = eval(where_items[0][0])\n",
    "    m = where_items[0][1]\n",
    "    b = where_items[0][2]\n",
    "    model_db = pickle.loads(base64.b64decode(where_items[0][7]))\n",
    "    _, vectorizer, _ = create_bag_of_words(solutions, v, binary=b, min_df=m)\n",
    "    train_data_features = vectorizer.transform(exercise_sol)\n",
    "    document_topic = model_db.transform(train_data_features)\n",
    "    return document_topic\n",
    "\n",
    "exercise_sol = [\"\"\"\n",
    "def colisao(ret1x1,ret1y1,ret1x2,ret1y2,ret2x1,ret2y1,ret2x2,ret2y2):\n",
    "    if ret1y1>ret2y1 and ret1y1>ret2y2 and ret1y2>ret2y1 and ret1y2>ret2y2:\n",
    "        return False\n",
    "    elif ret1x1>ret2x1 and ret1x1>ret2x2 and ret1x2>ret2x1 and ret1x2>ret2x1:\n",
    "        return False\n",
    "    elif ret1y1<ret2y1 and ret1y1<ret2y2 and ret1y2<ret2y1 and ret1y2<ret2y2:\n",
    "        return False\n",
    "    elif ret1x1<ret2x1 and ret1x1<ret2x2 and ret1x2<ret2x1 and ret1x2<ret2x1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\"\"\"]\n",
    "\n",
    "\n",
    "\n",
    "document_topic = assign_to_cluster(exp_id, solutions, exercise_sol)\n",
    "print(document_topic)\n",
    "# print(document_clusters)\n",
    "max_idx = np.argsort(document_topic[0])[::-1]\n",
    "for i in max_idx:\n",
    "    print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    def get_words():\n",
    "        return ['aborto',\n",
    " 'advirdes',\n",
    " 'adviéreis',\n",
    " 'alcatraz',\n",
    " 'amoladura',\n",
    " 'anticolérico',\n",
    " 'arborista',\n",
    " 'arpear',\n",
    " 'atomismo',\n",
    " 'barão',\n",
    " 'bit',\n",
    " 'boateiro',\n",
    " 'borbulhento',\n",
    " 'cabular',\n",
    " 'cacheiro',\n",
    " 'cagaçal',\n",
    " 'caleira',\n",
    " 'candelabro',\n",
    " 'carcereiro',\n",
    " 'centro',\n",
    " 'cirzo',\n",
    " 'cobiçoso',\n",
    " 'confessor',\n",
    " 'convêm',\n",
    " 'crestar',\n",
    " 'crápula',\n",
    " 'cólico',\n",
    " 'delirar',\n",
    " 'delínquo',\n",
    " 'destingir',\n",
    " 'divindade',\n",
    " 'dragagem',\n",
    " 'drogaria',\n",
    " 'duodecénio',\n",
    " 'dúbio',\n",
    " 'entretendo',\n",
    " 'equitativo',\n",
    " 'escorrer',\n",
    " 'espaldar',\n",
    " 'esticanço',\n",
    " 'europeízem',\n",
    " 'exultar',\n",
    " 'famigerado',\n",
    " 'fanático',\n",
    " 'festinhas',\n",
    " 'filonianos',\n",
    " 'gauchai',\n",
    " 'generante',\n",
    " 'higienizar',\n",
    " 'humildade',\n",
    " 'imperturbado',\n",
    " 'inclusão',\n",
    " 'intercelular',\n",
    " 'intravável',\n",
    " 'isotónico',\n",
    " 'Kennedy',\n",
    " 'lamentar',\n",
    " 'linguístico',\n",
    " 'lixoso',\n",
    " 'luso',\n",
    " 'Lérida',\n",
    " 'Mark',\n",
    " 'matutar',\n",
    " 'multimédia',\n",
    " 'musicologia',\n",
    " 'Mussolini',\n",
    " 'nevoeirada',\n",
    " 'ogivado',\n",
    " 'OGMA',\n",
    " 'paludismo',\n",
    " 'panelada',\n",
    " 'particularista',\n",
    " 'penúltimo',\n",
    " 'persecução',\n",
    " 'pintalgar',\n",
    " 'predilecção',\n",
    " 'previne',\n",
    " 'regresso',\n",
    " 'repelir',\n",
    " 'ressentir',\n",
    " 'saberdes',\n",
    " 'sagaz',\n",
    " 'Schiller',\n",
    " 'segue',\n",
    " 'sigilar',\n",
    " 'somatotropas',\n",
    " 'sorrir',\n",
    " 'subtractivo',\n",
    " 'sustiveram',\n",
    " 'sustivéreis',\n",
    " 'séquito',\n",
    " 'terreno',\n",
    " 'trajo',\n",
    " 'traziam',\n",
    " 'troçar',\n",
    " 'vagão',\n",
    " 'virginalizar',\n",
    " 'vivificativo',\n",
    " 'voraz']\n",
    "    tests = []\n",
    "    words = get_words()\n",
    "    random.shuffle(words)\n",
    "    for word in words:\n",
    "        i = random.randrange(0, len(word))\n",
    "        multiply = random.choice([2,3])\n",
    "        i = i*random.choice([1,multiply])\n",
    "        tests.append([word, i])\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    def calculate_colisao(ret1x1,ret1y1,ret1x2,ret1y2,ret2x1,ret2y1,ret2x2,ret2y2):\n",
    "        if ret1y1>ret2y1 and ret1y1>ret2y2 and ret1y2>ret2y1 and ret1y2>ret2y2:\n",
    "            return False\n",
    "        elif ret1x1>ret2x1 and ret1x1>ret2x2 and ret1x2>ret2x1 and ret1x2>ret2x1:\n",
    "            return False\n",
    "        elif ret1y1<ret2y1 and ret1y1<ret2y2 and ret1y2<ret2y1 and ret1y2<ret2y2:\n",
    "            return False\n",
    "        elif ret1x1<ret2x1 and ret1x1<ret2x2 and ret1x2<ret2x1 and ret1x2<ret2x1:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    num_tests = 5\n",
    "    tests = []\n",
    "    while len(tests) < num_tests:\n",
    "        r1x1 = random.randrange(9)\n",
    "        r1y1 = random.randrange(9)\n",
    "        r1x2 = random.randrange(10)\n",
    "        r1y2 = random.randrange(10)\n",
    "        while r1x2 <= r1x1:\n",
    "            r1x2 = random.randrange(10)\n",
    "        while r1y2 <= r1y1:\n",
    "            r1y2 = random.randrange(10)\n",
    "        r2x1 = random.randrange(9)\n",
    "        r2y1 = random.randrange(9)\n",
    "        r2x2 = random.randrange(10)\n",
    "        r2y2 = random.randrange(10)\n",
    "        while r2x2 <= r2x1:\n",
    "            r2x2 = random.randrange(10)\n",
    "        while r2y2 <= r2y1:\n",
    "            r2y2 = random.randrange(10)\n",
    "        resposta = calculate_colisao(r1x1, r1y1, r1x2, r1y2, r2x1, r2y1, r2x2, r2y2)\n",
    "        \n",
    "        if len(tests)%2 and resposta == True:\n",
    "            continue\n",
    "            \n",
    "        elif not len(tests)%2 and resposta == False:\n",
    "            continue\n",
    "        test_case = [r1x1, r1y1, r1x2, r1y2, r2x1, r2y1, r2x2, r2y2]\n",
    "        tests.append(test_case)\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 2, 9, 6, 8, 1, 9, 5],\n",
       " [8, 5, 9, 7, 1, 0, 6, 8],\n",
       " [7, 0, 9, 3, 2, 3, 9, 4],\n",
       " [0, 8, 2, 9, 3, 4, 6, 8],\n",
       " [7, 1, 8, 5, 6, 4, 8, 8]]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4]\n",
      "[2, 1]\n",
      "[9, 0]\n",
      "[1, 0]\n",
      "[3, 5]\n",
      "[5, 0]\n",
      "[3, 6]\n",
      "[9, 2]\n",
      "[4, 0]\n",
      "[4, 8]\n",
      "[7, 9]\n",
      "[9, 2]\n",
      "[8, 5]\n",
      "[3, 8]\n",
      "[5, 8]\n",
      "[5, 7]\n",
      "[9, 0]\n",
      "[7, 7]\n",
      "[2, 5]\n",
      "[2, 5]\n"
     ]
    }
   ],
   "source": [
    "cases = generate()\n",
    "for i in cases:\n",
    "    i = i.replace('\\n','')\n",
    "    i = i.split(' ')\n",
    "    new_i = []\n",
    "    for elem in i:\n",
    "        new_i.append(int(elem))\n",
    "    print(new_i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
