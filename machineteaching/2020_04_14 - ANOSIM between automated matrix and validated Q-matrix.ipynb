{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import base64\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import rpy2\n",
    "\n",
    "# DB \n",
    "import psycopg2\n",
    "from django.conf import settings\n",
    "\n",
    "# Learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "from skbio.stats.distance import anosim\n",
    "from skbio import DistanceMatrix\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import analyzer\n",
    "from tokenizer import create_bag_of_words\n",
    "from vectorizer import NCutVectorizer\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: ggplot2\n",
      "\n",
      "R[write to console]: Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘proxy’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    as.dist, dist\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:base’:\n",
      "\n",
      "    as.matrix\n",
      "\n",
      "\n",
      "R[write to console]: This is vegan 2.5-6\n",
      "\n",
      "R[write to console]: ── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "R[write to console]: \u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.1     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4     \n",
      "\n",
      "R[write to console]: ── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(factoextra)\n",
    "library(proxy)\n",
    "library(permute)\n",
    "library(lattice)\n",
    "library(vegan)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get solutions from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problems to be used: 132\n",
      "Solutions to be used: 54\n",
      "Got 54 documents\n"
     ]
    }
   ],
   "source": [
    "## Cleaning database\n",
    "last_id = 132\n",
    "# problems = Problem.objects.filter(id__gt=last_id)\n",
    "# # solutions_obj = Solution.objects.filter(problem__in=problems).update(ignore=True)\n",
    "# print(\"Problems to be ignored: %d\" % problems.count())\n",
    "\n",
    "problems = Problem.objects.filter(id__lte=last_id)\n",
    "# problems = Problem.objects.all()\n",
    "print(\"Problems to be used: %d\" % problems.count())\n",
    "\n",
    "solutions_obj = Solution.objects.filter(problem__in=problems, ignore=False).order_by('problem_id')\n",
    "# solutions_obj = Solution.objects.all().order_by('id')\n",
    "print(\"Solutions to be used: %d\" % solutions_obj.count())\n",
    "\n",
    "docs_id = []\n",
    "questions = []\n",
    "solutions = []\n",
    "clusters = []\n",
    "questions_idx = []\n",
    "\n",
    "# Fill separated structures\n",
    "for sol in solutions_obj:\n",
    "    questions_idx.append(sol.problem.id)\n",
    "    docs_id.append(sol.id)\n",
    "    questions.append(sol.problem.content)\n",
    "    solutions.append(sol.content)\n",
    "    clusters.append(sol.cluster.id)\n",
    "\n",
    "print(\"Got %d documents\" %(solutions_obj.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(user = settings.DATABASES[\"default\"][\"USER\"],\n",
    "                                  password = settings.DATABASES[\"default\"][\"PASSWORD\"],\n",
    "                                  host = settings.DATABASES[\"default\"][\"HOST\"],\n",
    "                                  port = settings.DATABASES[\"default\"][\"PORT\"],\n",
    "                                  database = settings.DATABASES[\"default\"][\"NAME\"])\n",
    "connection.autocommit=True\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_where_items(exp_id, cols, table):\n",
    "    query = \"SELECT %s from %s where experiment_id = %s\" % (\", \".join(cols), table, exp_id) \n",
    "    cursor.execute(query)\n",
    "    where_items = cursor.fetchall()\n",
    "    return where_items\n",
    "\n",
    "def get_original_q_matrix():\n",
    "    # Get voted concepts per solution\n",
    "    concepts = SolutionConcept.objects.all()\n",
    "    MIN_THRESHOLD = 0.5\n",
    "    agreed_concepts = defaultdict(list)\n",
    "    agreed_concepts_len = {}\n",
    "    \n",
    "    # Count concept agreement per solution\n",
    "    count_per_solution = dict(concepts.values_list('solution__id').annotate(count=Count('user', distinct=True)))\n",
    "\n",
    "    # Filter out the concepts that didn't have agreement (50% of evaluators voted for it)\n",
    "    for solution_id in docs_id:\n",
    "        max_votes = count_per_solution[solution_id]\n",
    "        concepts_per_solution = dict(concepts.filter(solution__id=solution_id).values_list('concept').annotate(\n",
    "            count=Count(\"concept\")))\n",
    "        for concept, value in concepts_per_solution.items():\n",
    "            if value >= (max_votes * MIN_THRESHOLD):\n",
    "                agreed_concepts[solution_id].append(concept)\n",
    "        agreed_concepts_len[solution_id] = len(agreed_concepts[solution_id])\n",
    "        agreed_concepts_all = list(chain.from_iterable(agreed_concepts.values()))\n",
    "        agreed_concepts_set = set(agreed_concepts_all)\n",
    "        \n",
    "    concept_idx = np.asarray(list(agreed_concepts_set))\n",
    "    q_matrix = np.zeros((len(docs_id), len(concept_idx)))\n",
    "\n",
    "    for q_idx, question_id in enumerate(docs_id):\n",
    "        used_concepts = agreed_concepts[question_id]\n",
    "        q_matrix[q_idx, np.where(np.isin(concept_idx, used_concepts))] = 1\n",
    "    return q_matrix\n",
    "\n",
    "def transform_data(q_matrix, q_matrix_hat):\n",
    "    data = {}\n",
    "    # Calculate similarities among questions in Q-Matrix and estimated Q-Matrix\n",
    "    data['question_similarity'] = cosine_similarity(q_matrix)\n",
    "    data['question_distance'] = cosine_distances(q_matrix)\n",
    "    data['question_hat_similarity'] = cosine_similarity(q_matrix_hat)\n",
    "    data['question_hat_distance'] = cosine_distances(q_matrix_hat)\n",
    "    error = data['question_similarity'] - data['question_hat_similarity']\n",
    "\n",
    "    # Calculate total error, RMSE and CMD\n",
    "    data['error'] = np.sqrt(np.sum(np.power(error,2)))\n",
    "    data['rmse'] = np.sqrt(np.mean(np.power(error,2)))\n",
    "    qs = data['question_similarity']\n",
    "    qs_hat = data['question_hat_similarity']\n",
    "    data['cmd'] = 1-np.trace(np.dot(qs,qs_hat))/(np.linalg.norm(qs)*np.linalg.norm(qs_hat))\n",
    "    return data\n",
    "\n",
    "def calculate_anosim(item):\n",
    "    row = {}\n",
    "#     row['Experiment ID'] = item['exp_id']\n",
    "#     row['Method'] = \"%s (%d attempts)\" % (item['method'].upper(), item['attempts'])\n",
    "#     row['Concept'] = item['concepts']\n",
    "    dm = DistanceMatrix(item['question_distance'])\n",
    "    stats_list = []\n",
    "    p_values = []\n",
    "    for i in range(2, 40):\n",
    "        model = AgglomerativeClustering(n_clusters=i, \n",
    "#                                         affinity='cosine',\n",
    "                                        affinity='precomputed',\n",
    "                                        linkage='complete').fit(item['question_hat_distance'])\n",
    "#             item['q_matrix_hat'].T)\n",
    "        stats = anosim(dm, model.labels_, permutations=9999)\n",
    "        stats_list.append(stats['test statistic'])\n",
    "        p_values.append(stats['p-value'])\n",
    "    stats_list = np.asarray(stats_list)\n",
    "    p_values = np.asarray(p_values)\n",
    "    if np.any(np.where(p_values < 0.1)):\n",
    "        row['Statistical significant (p < 0.1)'] = True\n",
    "        row['Agg Concepts'] = np.where(p_values < 0.1)[0]+2\n",
    "#         row['R Statistic'] = np.asarray(stats_list)[np.where(np.asarray(p_values) < 0.1)]\n",
    "        sig_stats = stats_list[np.where(p_values < 0.1)]\n",
    "        row['R Statistic'] = \"%.2f at %d\" % (np.max(sig_stats), np.where(stats_list == np.max(sig_stats))[0]+2)\n",
    "    else:\n",
    "        row['Statistical significant (p < 0.1)'] = False\n",
    "        row['Agg Concepts'] = '--'\n",
    "        row['R Statistic'] = '--'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve original Q-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 166 ms, sys: 4.03 ms, total: 170 ms\n",
      "Wall time: 7.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54, 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "q_matrix_original = get_original_q_matrix()\n",
    "q_matrix_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save automated Q-matrix\n",
    "with open('data/tese/q_matrix_original.pkl', 'wb') as pklfile:\n",
    "    pickle.dump(q_matrix_original, pklfile)\n",
    "np.savetxt(\"data/tese/q_matrix_original.csv\", q_matrix_original, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve automated Q-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51 ms, sys: 0 ns, total: 51 ms\n",
      "Wall time: 2.16 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54, 12)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "exp_id = 26\n",
    "cols = [\"vectorizer\", \"min_df\", \"is_binary\", \"model\"]\n",
    "table = \"experiments_solution\"\n",
    "where_items = get_where_items(exp_id, cols, table)[0]\n",
    "v = eval(where_items[0])\n",
    "m = where_items[1]\n",
    "b = where_items[2]\n",
    "vectorizer_params={'ngram_range': (1,3)}\n",
    "train_data_features, vectorizer, _ = create_bag_of_words(solutions, v, binary=b, min_df=m, \n",
    "                                                         vectorizer_params=vectorizer_params)\n",
    "\n",
    "model = where_items[3]\n",
    "model_db = pickle.loads(base64.b64decode(model))\n",
    "q_matrix_automated = model_db.transform(train_data_features)\n",
    "# word_topic = model_db.components_.T\n",
    "data.append(transform_data(q_matrix_original, q_matrix_automated))\n",
    "q_matrix_automated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save questions ids\n",
    "with open('data/tese/train_data_features.pkl', 'wb') as pklfile:\n",
    "    pickle.dump(train_data_features, pklfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save questions ids\n",
    "with open('data/tese/questions_idx.pkl', 'wb') as pklfile:\n",
    "    pickle.dump(questions_idx, pklfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save automated Q-matrix\n",
    "with open('data/tese/q_matrix_automated.pkl', 'wb') as pklfile:\n",
    "    pickle.dump(q_matrix_automated, pklfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve refined Q-Matrix (automated after analysis)\n",
    "- 1 concept per solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_set = list(set(clusters))\n",
    "q_matrix_analysis = np.zeros((len(docs_id), len(set(clusters))))\n",
    "for idx, cluster in enumerate(clusters):\n",
    "    q_matrix_analysis[idx, cluster_set.index(cluster)]= 1\n",
    "\n",
    "data.append(transform_data(q_matrix_original, q_matrix_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analyzed Q-matrix\n",
    "with open('data/tese/q_matrix_refined.pkl', 'wb') as pklfile:\n",
    "    pickle.dump(q_matrix_analysis, pklfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 86.9 ms, total: 1min 20s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = []\n",
    "for item in data:\n",
    "    row = calculate_anosim(item)\n",
    "    df.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statistical significant (p &lt; 0.1)</th>\n",
       "      <th>Agg Concepts</th>\n",
       "      <th>R Statistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...</td>\n",
       "      <td>0.45 at 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>0.28 at 26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Statistical significant (p < 0.1)  \\\n",
       "0                               True   \n",
       "1                               True   \n",
       "\n",
       "                                        Agg Concepts R Statistic  \n",
       "0  [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17...  0.45 at 36  \n",
       "1  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...  0.28 at 26  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.6 s, sys: 88 ms, total: 56.7 s\n",
      "Wall time: 56.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "item = data[0]\n",
    "dm = DistanceMatrix(item['question_distance'])\n",
    "row = {}\n",
    "stats_list = []\n",
    "p_values = []\n",
    "for i in range(2, 50):\n",
    "    model = AgglomerativeClustering(n_clusters=i, \n",
    "                                    affinity='precomputed',\n",
    "                                    linkage='complete').fit(item['question_hat_distance'].T)\n",
    "    stats = anosim(dm, model.labels_, permutations=9999)\n",
    "    stats_list.append(stats['test statistic'])\n",
    "    p_values.append(stats['p-value'])\n",
    "stats_list = np.asarray(stats_list)\n",
    "p_values = np.asarray(p_values)\n",
    "if np.any(np.where(p_values < 0.1)):\n",
    "    row['Statistical significant (p < 0.1)'] = True\n",
    "    row['Agg Concepts'] = np.where(p_values < 0.1)[0]+2\n",
    "#         row['R Statistic'] = np.asarray(stats_list)[np.where(np.asarray(p_values) < 0.1)]\n",
    "    sig_stats = stats_list[np.where(p_values < 0.1)]\n",
    "    row['R Statistic'] = \"%.2f at %d\" % (np.max(sig_stats), np.where(stats_list == np.max(sig_stats))[0]+2)\n",
    "else:\n",
    "    row['Statistical significant (p < 0.1)'] = False\n",
    "    row['Agg Concepts'] = '--'\n",
    "    row['R Statistic'] = '--'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09239082,  0.00778208, -0.01370905,  0.07522632,  0.09214763,\n",
       "        0.11787716,  0.14372703,  0.14617127,  0.15467822,  0.18518857,\n",
       "        0.18560334,  0.19081734,  0.17799965,  0.17821524,  0.19632512,\n",
       "        0.18886006,  0.19639434,  0.19478641,  0.20161662,  0.2031313 ,\n",
       "        0.25118278,  0.25021716,  0.28054846,  0.29420365,  0.30536793,\n",
       "        0.30152154,  0.31298456,  0.3505234 ,  0.3383922 ,  0.34301988,\n",
       "        0.36702849,  0.35814844,  0.34904215,  0.36677037,  0.4510502 ,\n",
       "        0.44531117,  0.34797782,  0.35420731,  0.3891619 ,  0.37883089,\n",
       "        0.35393448,  0.34367382,  0.29615927,  0.28457106,  0.21653765,\n",
       "        0.056922  ,  0.10002006,  0.19312763])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.332e-01, 4.000e-01, 5.777e-01, 3.920e-02, 1.950e-02, 6.100e-03,\n",
       "       1.200e-03, 2.600e-03, 1.700e-03, 8.000e-04, 6.000e-04, 1.200e-03,\n",
       "       1.700e-03, 3.500e-03, 2.000e-03, 2.000e-03, 1.800e-03, 3.100e-03,\n",
       "       3.300e-03, 2.500e-03, 8.000e-04, 1.400e-03, 3.000e-04, 3.000e-04,\n",
       "       3.000e-04, 5.000e-04, 1.000e-04, 2.000e-04, 3.000e-04, 7.000e-04,\n",
       "       4.000e-04, 6.000e-04, 1.000e-03, 7.000e-04, 1.000e-04, 5.000e-04,\n",
       "       2.800e-03, 6.900e-03, 3.400e-03, 5.700e-03, 9.600e-03, 1.910e-02,\n",
       "       4.510e-02, 6.280e-02, 1.331e-01, 3.873e-01, 3.165e-01, 2.244e-01])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "        20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "        37, 38, 39, 40, 41, 42, 43]),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(p_values  < 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07522632, 0.09214763, 0.11787716, 0.14372703, 0.14617127,\n",
       "       0.15467822, 0.18518857, 0.18560334, 0.19081734, 0.17799965,\n",
       "       0.17821524, 0.19632512, 0.18886006, 0.19639434, 0.19478641,\n",
       "       0.20161662, 0.2031313 , 0.25118278, 0.25021716, 0.28054846,\n",
       "       0.29420365, 0.30536793, 0.30152154, 0.31298456, 0.3505234 ,\n",
       "       0.3383922 , 0.34301988, 0.36702849, 0.35814844, 0.34904215,\n",
       "       0.36677037, 0.4510502 , 0.44531117, 0.34797782, 0.35420731,\n",
       "       0.3891619 , 0.37883089, 0.35393448, 0.34367382, 0.29615927,\n",
       "       0.28457106])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_list[np.where(p_values  < 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 12)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_matrix_hat = q_matrix_automated\n",
    "q_matrix = q_matrix_original\n",
    "q_matrix_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 2\n",
      "[1] 3\n",
      "[1] 4\n",
      "[1] 5\n",
      "[1] 6\n",
      "[1] 7\n",
      "[1] 8\n",
      "[1] 9\n",
      "[1] 10\n",
      "[1] 11\n",
      "[1] 12\n",
      "[1] 13\n",
      "[1] 14\n",
      "[1] 15\n",
      "    k         R     signif\n",
      "1   5 0.1409537 0.00109989\n",
      "2   6 0.1225760 0.00699930\n",
      "3   7 0.1710049 0.00039996\n",
      "4   8 0.1910186 0.00019998\n",
      "5   9 0.1936974 0.00049995\n",
      "6  10 0.1960702 0.00039996\n",
      "7  11 0.1982769 0.00029997\n",
      "8  12 0.2064476 0.00079992\n",
      "9  13 0.2064535 0.00109989\n",
      "10 14 0.2067765 0.00119988\n",
      "11 15 0.1874218 0.00299970\n"
     ]
    }
   ],
   "source": [
    "%%R -i q_matrix -i q_matrix_hat -o anosim_data\n",
    "# data <- read.csv('q_matrix_automated.csv', header=FALSE)\n",
    "# data_original <-read.csv('q_matrix_original.csv', header=FALSE)\n",
    "\n",
    "d <- dist(q_matrix_hat, method = \"euclidean\")\n",
    "d_original <- dist(q_matrix, method = \"jaccard\")\n",
    "res.hc <- hclust(d=d, method = \"ward.D2\")\n",
    "\n",
    "stats <- c()\n",
    "stats$k <- c()\n",
    "stats$R <- c()\n",
    "stats$signif <- c()\n",
    "\n",
    "for (k in c(2:15))\n",
    "{\n",
    "  print(k)\n",
    "  clusterCut <- cutree(res.hc, k)\n",
    "  a <- anosim(d_original, clusterCut, permutations = 10000)\n",
    "  stats$k <- c(stats$k, k)\n",
    "  stats$R <- c(stats$R, a$statistic)\n",
    "  stats$signif <- c(stats$signif, a$signif)\n",
    "}\n",
    "\n",
    "anosim_data <- data.frame(stats)\n",
    "anosim_data %>% filter(signif < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>R</th>\n",
       "      <th>signif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.447755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.167183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.017161</td>\n",
       "      <td>0.632037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.140954</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.122576</td>\n",
       "      <td>0.006999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.171005</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.191019</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.193697</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.196070</td>\n",
       "      <td>0.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.198277</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.206448</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.206454</td>\n",
       "      <td>0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.206777</td>\n",
       "      <td>0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.187422</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k         R    signif\n",
       "1    2  0.004897  0.447755\n",
       "2    3  0.032715  0.167183\n",
       "3    4 -0.017161  0.632037\n",
       "4    5  0.140954  0.001100\n",
       "5    6  0.122576  0.006999\n",
       "6    7  0.171005  0.000400\n",
       "7    8  0.191019  0.000200\n",
       "8    9  0.193697  0.000500\n",
       "9   10  0.196070  0.000400\n",
       "10  11  0.198277  0.000300\n",
       "11  12  0.206448  0.000800\n",
       "12  13  0.206454  0.001100\n",
       "13  14  0.206777  0.001200\n",
       "14  15  0.187422  0.003000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anosim_automated = anosim_data\n",
    "anosim_automated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_matrix_hat = q_matrix_analysis\n",
    "q_matrix = q_matrix_original\n",
    "q_matrix_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 2\n",
      "[1] 3\n",
      "[1] 4\n",
      "[1] 5\n",
      "[1] 6\n",
      "[1] 7\n",
      "[1] 8\n",
      "[1] 9\n",
      "[1] 10\n",
      "[1] 11\n",
      "[1] 12\n",
      "[1] 13\n",
      "[1] 14\n",
      "[1] 15\n",
      "    k         R     signif\n",
      "1   3 0.1392252 0.00049995\n",
      "2   4 0.1263954 0.00159984\n",
      "3   5 0.1180005 0.00599940\n",
      "4   6 0.1177108 0.00689931\n",
      "5   7 0.1209506 0.00449955\n",
      "6   8 0.1265794 0.00399960\n",
      "7   9 0.1258535 0.00559944\n",
      "8  10 0.1370063 0.00559944\n",
      "9  11 0.1464021 0.00359964\n",
      "10 12 0.1402808 0.00439956\n",
      "11 13 0.1387233 0.00829917\n",
      "12 14 0.1578091 0.00469953\n",
      "13 15 0.1516825 0.00369963\n"
     ]
    }
   ],
   "source": [
    "%%R -i q_matrix -i q_matrix_hat -o anosim_data\n",
    "# data <- read.csv('q_matrix_automated.csv', header=FALSE)\n",
    "# data_original <-read.csv('q_matrix_original.csv', header=FALSE)\n",
    "\n",
    "d <- dist(q_matrix_hat, method = \"euclidean\")\n",
    "d_original <- dist(q_matrix, method = \"jaccard\")\n",
    "res.hc <- hclust(d=d, method = \"ward.D2\")\n",
    "\n",
    "stats <- c()\n",
    "stats$k <- c()\n",
    "stats$R <- c()\n",
    "stats$signif <- c()\n",
    "\n",
    "for (k in c(2:15))\n",
    "{\n",
    "  print(k)\n",
    "  clusterCut <- cutree(res.hc, k)\n",
    "  a <- anosim(d_original, clusterCut, permutations = 10000)\n",
    "  stats$k <- c(stats$k, k)\n",
    "  stats$R <- c(stats$R, a$statistic)\n",
    "  stats$signif <- c(stats$signif, a$signif)\n",
    "}\n",
    "\n",
    "anosim_data <- data.frame(stats)\n",
    "anosim_data %>% filter(signif < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
