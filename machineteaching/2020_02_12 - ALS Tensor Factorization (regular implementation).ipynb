{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CONCEPTS = 2\n",
    "N_STUDENTS = 10\n",
    "N_ATTEMPTS = 3\n",
    "N_QUESTIONS = 5\n",
    "\n",
    "# Algorithm parameters\n",
    "INIT = 3\n",
    "MAX_ITER = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS Tensor Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als_tensor_factorization(student_performance, n_concepts=2, init=3, max_iter=100):\n",
    "    \n",
    "    # Get values from student performance tensor shape\n",
    "    n_students, n_questions, n_attempts = student_performance.shape\n",
    "    \n",
    "    # Create student knowledge tensor\n",
    "    student_knowledge = np.zeros((n_students, n_concepts, n_attempts))\n",
    "\n",
    "    error_run = []\n",
    "    error_total_run = []\n",
    "    student_performance_pred_run = []\n",
    "    \n",
    "    # Several starts\n",
    "    for run in range(init):\n",
    "        error = []\n",
    "        student_performance_pred_list = []\n",
    "    #     q_matrix = np.random.rand(N_QUESTIONS, N_CONCEPTS)\n",
    "\n",
    "        for attempt in range(N_ATTEMPTS):\n",
    "            student_knowledge[:, :, attempt] = np.random.rand(n_students, n_concepts)\n",
    "\n",
    "        # Phase 1: prediction\n",
    "        student_performance_pred = np.zeros(student_performance.shape)\n",
    "        for i in range(max_iter):\n",
    "\n",
    "            # Update Q: Q = (T'T)^(-1)T'Y = T^(-1)Y\n",
    "            # (T'T)^(-1)\n",
    "            student_knowledge_transposed = np.zeros((n_concepts, n_concepts, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                student_knowledge_transposed[:, :, attempt] = np.dot(student_knowledge[:, :, attempt].T, \n",
    "                                                                     student_knowledge[:, :, attempt])\n",
    "            student_knowledge_transposed = student_knowledge_transposed.sum(axis=2)\n",
    "            student_knowledge_transposed_inv = np.linalg.pinv(student_knowledge_transposed)\n",
    "            \n",
    "            # T'Y\n",
    "            TY = np.zeros((n_concepts, n_questions, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                TY[:, :, attempt] = np.dot(student_knowledge[:, :, attempt].T, \n",
    "                                           student_performance[:, :, attempt])\n",
    "            TY = TY.sum(axis=2)\n",
    "            \n",
    "            ## TODO: add regularization parameters (lambda)\n",
    "            # Q = (T'T)^(-1)T'Y\n",
    "            q_matrix = np.dot(student_knowledge_transposed_inv, TY)\n",
    "            # Impose non-negativity constraint\n",
    "            q_matrix[q_matrix < 0] = 0\n",
    "            # Normalize rows to sum one\n",
    "            row_sums = q_matrix.sum(axis=0, keepdims=True)\n",
    "            q_matrix = q_matrix / row_sums\n",
    "            \n",
    "            \n",
    "            # Update T: T = YQ'(QQ')^(-1) = YQ^(-1)\n",
    "            # (QQ')^(-1)\n",
    "            q_matrix_transpose_inv = np.linalg.pinv(np.dot(q_matrix, q_matrix.T))\n",
    "            \n",
    "            # YQ'\n",
    "            YQ = np.zeros((n_students, n_concepts, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                YQ[:, :, attempt] = np.dot(student_performance[:, :, attempt], q_matrix.T)\n",
    "                \n",
    "            # T = YQ'(QQ')^(-1)\n",
    "            for attempt in range(n_attempts):\n",
    "                student_knowledge[:, :, attempt] = np.dot(YQ[:, :, attempt], q_matrix_transpose_inv)\n",
    "                \n",
    "            # Y = TQ\n",
    "            for attempt in range(n_attempts):\n",
    "                student_performance_pred[:, :, attempt] = np.dot(student_knowledge[:, :, attempt], q_matrix)\n",
    "                \n",
    "            \n",
    "            diff = np.zeros((n_students, n_questions, n_attempts))\n",
    "            for attempt in range(n_attempts):\n",
    "                diff[:, :, attempt] = student_performance[:, :, attempt] - student_performance_pred[:, :, attempt]\n",
    "            # Frobenius norm (norm-2)\n",
    "            error.append(np.sqrt(np.sum(np.power(diff, 2))))\n",
    "            \n",
    "            student_performance_pred_iter = student_performance_pred.copy()\n",
    "            student_performance_pred_list.append(student_performance_pred_iter)\n",
    "        student_performance_pred_run.append(student_performance_pred_list)\n",
    "        error_run.append(error)\n",
    "        error_total_run.append(error[-1])\n",
    "                \n",
    "            \n",
    "    return np.asarray(student_performance_pred_run), np.asarray(error_run), error_total_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58543776 0.67279455 0.67279455 0.64561084 0.8336423 ]]\n",
      "[[0.84251784 0.66021096 1.17567053 0.65414206 0.93900949]]\n",
      "[[0.78357543 0.81184836 0.80766993 0.81184836 0.83941291]]\n",
      "[[0.66980563 0.66980563 0.61514976 0.67642634 0.6071293 ]]\n",
      "[[0.74016358 0.74016358 0.75374345 0.74016358 0.75374345]]\n",
      "[[0.4601472  0.57590317 0.57590317 0.71025061 0.61132091]]\n",
      "[[0.80651603 0.88864907 0.80651603 0.88864907 0.88864907]]\n",
      "[[0.61723735 0.71835617 0.71835617 0.71835617 0.57700709]]\n",
      "[[0.71087886 0.88862715 0.71087886 0.70746038 0.70746038]]\n",
      "[[0.56842574 0.56842574 0.47643974 0.64895311 0.51998945]]\n",
      "[[0.65996133 0.65996133 0.55686638 0.70429671 0.55686638]]\n",
      "[[0.3747665  0.43826424 0.53335403 0.50923123 0.43826424]]\n",
      "[[0.5273482  0.45771781 0.63232432 0.44388233 0.80257103]]\n",
      "[[0.75286462 0.76790699 0.76790699 0.84582139 0.98020756]]\n",
      "[[0.68475227 0.68475227 0.58930654 0.60559517 0.58930654]]\n",
      "[[0.75223673 0.58059019 0.75223673 0.53766882 0.70969643]]\n",
      "[[0.61756325 0.96176382 0.67805682 0.81126997 0.55994511]]\n",
      "[[1.1306294  1.03480896 0.95525768 0.86579912 1.1306294 ]]\n",
      "[[0.91471032 0.91332072 0.70712084 0.85252252 0.91471032]]\n",
      "[[0.47899353 0.69112499 0.68792677 0.69112499 0.68792677]]\n",
      "[[0.68264057 0.58898675 0.68264057 0.57445778 0.71516783]]\n",
      "[[0.43292133 0.43292133 0.43080426 0.46896824 0.37839192]]\n",
      "[[0.71969884 0.6331844  0.65970907 0.71969884 0.48752424]]\n",
      "[[0.68878351 0.73587042 0.73587042 0.961223   0.67199962]]\n",
      "[[0.8450779  0.76570438 0.77301543 0.8450779  0.69272918]]\n",
      "[[0.58916016 0.74785158 0.72719708 0.74785158 0.74785158]]\n",
      "[[0.68071113 0.53960276 0.77388046 0.59987214 0.53960276]]\n",
      "[[0.58780425 0.58780425 0.57953795 0.65298117 0.46664148]]\n",
      "[[0.90142785 0.83709567 0.89593458 0.90142785 0.85213073]]\n",
      "[[0.50817231 0.63089084 0.64920403 0.64920403 0.63089084]]\n",
      "[[0.76442736 0.92666388 0.76442736 0.75665014 0.87802485]]\n",
      "[[0.77861989 0.35202301 0.53253398 0.34397176 0.69977282]]\n",
      "[[0.47848721 0.47800608 1.06569839 0.48483086 0.96972713]]\n",
      "[[0.95815225 0.83825987 0.83825987 0.83825987 0.95815225]]\n",
      "[[0.61213327 0.61213327 0.51185972 0.61213327 0.61213327]]\n",
      "[[0.589599   0.4708264  0.66658624 0.589599   0.71019389]]\n",
      "[[0.58371241 0.70943543 0.58371241 0.53119173 0.69435492]]\n",
      "[[0.55014837 0.41739629 0.76188658 0.34106401 0.60686496]]\n",
      "[[0.40691488 0.46769704 0.370044   0.46769704 0.370044  ]]\n",
      "[[0.79781303 0.87511697 0.65708421 0.88410121 0.85799736]]\n",
      "[[0.77075166 0.66602583 0.55401832 0.74888691 0.51410429]]\n",
      "[[0.63451911 0.58242073 0.63597154 0.63451911 0.63451911]]\n",
      "[[0.52409717 0.32545583 0.32545583 0.52409717 0.52409717]]\n",
      "[[0.72247341 0.72247341 0.51825016 0.69103339 0.72247341]]\n",
      "[[0.89341455 0.45463072 0.61091126 0.58909263 0.58909263]]\n",
      "[[0.38581356 0.33868091 0.35653478 0.64816937 0.33868091]]\n",
      "[[0.51893412 0.45759268 0.50072471 0.51893412 0.51893412]]\n",
      "[[0.84712808 0.88543655 0.66539546 0.88543655 0.53980118]]\n",
      "[[0.58378126 0.76468354 0.5164653  0.93324259 0.93324259]]\n",
      "[[0.79531574 0.33876169 0.37453462 0.68860975 0.3388706 ]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(50):\n",
    "    student_performance = generate_sample(noise)\n",
    "    student_performance[student_performance > 0.5] = 1\n",
    "    student_performance[student_performance < 0.5] = 0\n",
    "    q_matrix = als_tensor_factorization(student_performance, n_concepts=2, init=3, max_iter=50)\n",
    "    row_sums = q_matrix.sum(axis=0, keepdims=True)\n",
    "    print(row_sums)\n",
    "#     print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation 1 - Student Performance is the exact multiplication of  Q Matrix and Student Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(noise=0):\n",
    "    DENSITY = 0.8\n",
    "\n",
    "    # Create sparse q_matrix and normalize it to sum 1\n",
    "    q_matrix = sparse.rand(N_CONCEPTS, N_QUESTIONS, DENSITY).todense()\n",
    "    row_sums = q_matrix.sum(axis=0)\n",
    "    while not(np.all(row_sums)):\n",
    "        q_matrix = sparse.rand(N_CONCEPTS, N_QUESTIONS, DENSITY).todense()\n",
    "        row_sums = q_matrix.sum(axis=0)\n",
    "    q_matrix = q_matrix / row_sums\n",
    "\n",
    "    student_knowledge = np.zeros((N_STUDENTS, N_CONCEPTS, N_ATTEMPTS))\n",
    "    for attempt in range(N_ATTEMPTS):\n",
    "        student_knowledge[:, :, attempt] = sparse.rand(N_STUDENTS, N_CONCEPTS, DENSITY).todense()\n",
    "\n",
    "    student_performance = np.zeros((N_STUDENTS, N_QUESTIONS, N_ATTEMPTS))\n",
    "    for attempt in range(N_ATTEMPTS):\n",
    "        student_performance[:, :, attempt] = np.dot(student_knowledge[:, :, attempt], q_matrix)\n",
    "        \n",
    "    if noise:\n",
    "        noise = np.random.normal(0, noise, (N_STUDENTS, N_QUESTIONS, N_ATTEMPTS))\n",
    "        student_performance = student_performance + noise\n",
    "        \n",
    "    return student_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_performance = generate_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_performance_pred_run, error_run, error_total_run = als_tensor_factorization(\n",
    "    student_performance, n_concepts=2, init=1, max_iter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.99132192e-02, 1.47108740e-14, 1.51478071e-14, 1.59328638e-14]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation 2 - Student Performance is the multiplication of Q Matrix and Student Knowledge plus noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_performance = generate_sample(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_performance_pred_run, error_run, error_total_run = als_tensor_factorization(\n",
    "    student_performance, n_concepts=2, init=3, max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.28762926, 4.28232382, 4.278913  , 4.27662949, 4.27503454,\n",
       "        4.27387484, 4.27300197, 4.27232667, 4.27179325, 4.27136545,\n",
       "        4.27101855, 4.27073501, 4.27050189, 4.27030938, 4.27014987,\n",
       "        4.27001735, 4.26990701, 4.26981497, 4.26973808, 4.26967374,\n",
       "        4.26961986, 4.26957467, 4.26953675, 4.2695049 , 4.26947812,\n",
       "        4.26945559, 4.26943663, 4.26942067, 4.26940722, 4.26939588,\n",
       "        4.26938632, 4.26937826, 4.26937145, 4.26936571, 4.26936087,\n",
       "        4.26935678, 4.26935332, 4.26935041, 4.26934794, 4.26934586,\n",
       "        4.26934411, 4.26934262, 4.26934137, 4.26934031, 4.26933941,\n",
       "        4.26933865, 4.26933801, 4.26933747, 4.26933702, 4.26933663],\n",
       "       [4.36485323, 4.26647555, 4.26240973, 4.26119492, 4.26089667,\n",
       "        4.26105314, 4.26231548, 4.26365721, 4.26484984, 4.26582978,\n",
       "        4.26660365, 4.26720266, 4.2676623 , 4.26801439, 4.26828482,\n",
       "        4.26849369, 4.26865618, 4.26878363, 4.26888442, 4.26896481,\n",
       "        4.26902941, 4.26908171, 4.26912433, 4.26915926, 4.26918803,\n",
       "        4.26921183, 4.26923159, 4.26924805, 4.26926179, 4.2692733 ,\n",
       "        4.26928294, 4.26929104, 4.26929785, 4.26930358, 4.2693084 ,\n",
       "        4.26931247, 4.2693159 , 4.26931879, 4.26932123, 4.2693233 ,\n",
       "        4.26932504, 4.26932651, 4.26932775, 4.2693288 , 4.26932968,\n",
       "        4.26933043, 4.26933107, 4.2693316 , 4.26933205, 4.26933244],\n",
       "       [4.6356662 , 4.53295711, 4.39331609, 4.30163083, 4.28365603,\n",
       "        4.28019206, 4.29472762, 4.30312996, 4.30764854, 4.30303939,\n",
       "        4.29349346, 4.28707137, 4.28254471, 4.27928723, 4.27691194,\n",
       "        4.27516088, 4.27385678, 4.27287593, 4.27213107, 4.27156009,\n",
       "        4.27111841, 4.27077376, 4.27050259, 4.27028757, 4.27011583,\n",
       "        4.26997773, 4.26986599, 4.26977509, 4.26970076, 4.26963971,\n",
       "        4.26958938, 4.26954773, 4.26951316, 4.2694844 , 4.26946041,\n",
       "        4.26944036, 4.26942358, 4.26940951, 4.2693977 , 4.26938778,\n",
       "        4.26937943, 4.26937241, 4.26936649, 4.26936151, 4.2693573 ,\n",
       "        4.26935376, 4.26935077, 4.26934824, 4.26934611, 4.26934432]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation 3 - Student Performance contains only zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_performance = generate_sample(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_performance[student_performance > 0.5] = 1\n",
    "student_performance[student_performance < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_performance_pred_run, error_run, error_total_run = als_tensor_factorization(\n",
    "    student_performance, n_concepts=2, init=3, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = np.unravel_index(error_run.argmin(), error_run.shape)\n",
    "best_student_performance_pred = student_performance_pred_run[best_run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_student_performance_pred[best_student_performance_pred > 0.5] = 1\n",
    "best_student_performance_pred[best_student_performance_pred < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.67%\n"
     ]
    }
   ],
   "source": [
    "acc = 100*(np.logical_not(np.logical_xor(\n",
    "    student_performance, best_student_performance_pred)).sum())/(\n",
    "    student_performance.shape[0]*student_performance.shape[1]*student_performance.shape[2])\n",
    "print(\"Accuracy: %.2f%%\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9b3/8ddnMtk3srIEQpBFZBEIFEHFjdq6IUrrilRbf6JexK3tvfZ6W/vocutttdYdsV6XVhFxQ22tIooiAgqyirLLEhSyQCD79v39kZGrGCVkkjkzk/fz8ZhHJuecmbxPCO+cfM9mzjlERCS6+LwOICIi7U/lLiIShVTuIiJRSOUuIhKFVO4iIlHI73UAgOzsbFdQUOB1DBGRiLJ8+fIS51xOS/PCotwLCgpYtmyZ1zFERCKKmW37pnkalhERiUIqdxGRKKRyFxGJQip3EZEodNhyN7P/NbM9Zrb2S9MyzWyemW0MfMwITDczu8fMNpnZajMr7MjwIiLSstZsuT8GnHHItFuA+c65/sD8wOcAZwL9A4+pwIPtE1NERI7EYcvdOfcOUHbI5InA44HnjwPnfWn6E67ZEqCLmXVvr7AiItI6bR1z7+qc+wwg8DE3MD0P2PGl5XYGpn2NmU01s2Vmtqy4uLiNMUREpCXtvUPVWpjW4gXjnXMznXOjnHOjcnJaPMHqsC56aDEXPbS4Ta8VEYlmbS333V8MtwQ+7glM3wn0+tJyPYFdbY8nIiJt0dZyfwm4PPD8cmDul6b/KHDUzBig/IvhGxERCZ3DXlvGzGYBpwDZZrYTuA24HXjGzK4EtgMXBBb/J3AWsAmoAn7cAZlFROQwDlvuzrlLvmHW+BaWdcC0YEOJiEhwdIaqiEgUUrmLiEQhlbuISBRSuYuIRCGVu4hIFAqL2+y1lXOO2oYmr2OIiISdiN5y37WvhjVF5cxdWeR1FBGRsBLR5Z6TGk9yvJ8bnl7JbXPXUneEW/G6No2IRKuIHpaJ8/sY2C2V4b268PDCrawuKueByYV0T0/0OpqIiKciessdwGfGrWcP4oHJhWz4/ABn3/MuizaVeB1LRMRTEV/uXzhraHdemn4iWclxTHlkKfe/tYmmphavNiwiEvWiptwB+uak8OK0Ezj72B786bX1TP3bcsqr672OJSISclFV7gDJ8X7uuXg4v54wiAXr93Dufe+ybtd+r2OJiIRU1JU7gJlxxQl9mH31GGrqG5n04CKeW77T61giIiETleX+hZG9M3ll+jiG9+rCT+es4tYX1lDb0Oh1LBGRDhfV5Q7Nx8L//crjuObkvjy5dDsXzlhM0b5qr2OJiHSoqC93AH+Mj1vOHMhDU0aypbiSc+5ZyDsbir2OJSLSYTpFuX/h+4O78dL0E8lNTeDyR9+naG81zTePahud4Soi4Sqiz1CdffXYI35Nn+xkXph2PLe+sJYXVhRRUdvA3so6MpLjOiChiIg3OtWW+xeS4vz8+cJhFGQlUV5dz5l3L+T9rWVexxIRaTedstyh+XDJrmkJDO6RRkKsj4tnLuae+Rtp1FmtIhIFOm25fyE53s8r149jwrAe/HneBqY8spQ9+2u8jiUiEpROX+4AKfF+/nLRcP74w2NZsX0fZ969kAXr93gdS0SkzVTuAWbGhaN68fL0E8hOieeKRz/gD69+TH2j7vQkIpFH5X6IfrmpzL3uBC49Lp+H3t7CBTMWs6OsyutYIiJHROXegoTYGP77/KHcf2khm/dUcNY9C3l1zWdexxIRaTWV+7c4+9ju/OP6cRyVncy1T37If724hpp6XZtGRMKfyv0w8rOSmHPN8Uw96Sj+vmQ75z/wHpuLK7yOJSLyrVTurRDn9/GfZx3Do1d8h937a5hw77s8q0sIi0gYU7kfgVMH5vLP68cxNC+dn81ZxebiiqBOetK1aUSko6jcj1C39ASeumoMN4zvT0lFHWt3lbO3ss7rWCIiX9Gpy3321WPbdPGxGJ9x0+kDGNgtldr6Jn46Z5Vuxi0iYaVTl3uw0hNjyc9K4s1P9jBz4Rav44iIHKRyD1LX1HjOHtqdP722nmWf6sqSIhIeVO5BMjP+8IOh9MxI5LqnVlCm8XcRCQMq93aQlhDL/ZcWUlZZx83PrNT4u4h4TuXeTobkpfPLCYNYsL6YGe9s9jqOiHRyQZW7md1gZmvN7CMzuzEw7ddmVmRmKwOPs9onavi77Lh8zjm2O3e+vkF3dhIRT7W53M1sCHAVMBoYBpxjZv0Ds+9yzg0PPP7ZDjkjgpnxh0lDyc9MYvqsDymtqPU6koh0UsFsuR8DLHHOVTnnGoC3gfPbJ1bkSk2I5b5LR7C3qp6bntHx7yLijWDKfS1wkpllmVkScBbQKzDvOjNbbWb/a2YZQaeMMIN7pHPbhEG8s6GYB9/W+LuIhF6by9059zHwP8A84F/AKqABeBDoCwwHPgPubOn1ZjbVzJaZ2bLi4uK2xghbl47O59xhPbjz9fUs2VLqdRwR6WSC2qHqnHvEOVfonDsJKAM2Oud2O+canXNNwMM0j8m39NqZzrlRzrlROTk5wcQIS2bGf08aSkFWMtfPWkGJxt9FJISCPVomN/AxH5gEzDKz7l9a5Hyah286pZR4P/dPLqS8up6bZq8M6gqSIiJHItjj3J8zs3XAy8A059xe4I9mtsbMVgOnAjcFGzKSHdM9jV+fO5iFG0t44K1NXscRkU7CH8yLnXPjWpg2JZj3jCStvaLkxd/pxdItpdz1xgZGFmRwfN/sDk4mIp2dzlANATPj9+cPpSA7mRueXknxAY2/i0jHUrmHSHK8nwcmF3Kgpp4bZ6/Q+LuIdCiVewgN7JbGb84dwqJNpdz3psbfRaTjqNxD7IJRPZk0Io+/zN9AeXV9UO+le7CKyDdRuYeYmfG784fQNyeFzcUV1DU0eR1JRKKQyt0DSXF+7r+0kMYmx+biCo2/i0i7U7l75OhuqRRkJbO/poE7X1/vdRwRiTIqdw/lpMaTkxrPAws28/pHn3sdR0SiiMrdYwWZSRzbM52fPrOKrSWVXscRkSihcveYz2c8MLmQmBjj2r8vp6quwetIIhIFVO5hoGdGEvdcPIL1uw/wn8+vwTntYBWR4Kjcw8RJA3K4+bsDeHHlLv62ZJvXcUQkwqncw8i0U/sxfmAuv31lHcu37fU6johEMJV7GPH5jD9fNJzu6YlMe/JD3eBDRNpM5R5m0hNjefCyQvZW1TH9qRU0NOoMVhE5cir3MDS4Rzr/ff5QFm8p5U86wUlE2kDlHqZ+MLInk4/L56G3t/CvtZ95HUdEIozKPYz9asIghvXqws/mrGZzcYXXcUQkgqjcw1i8P4YHJxcS5/dx7d+XU1mrE5xEpHVU7mGuR5dE7r1kBJv2VHCLTnASkVZSuUeAE/pl89PvHc3Lq3bx2Hufeh1HRCKAyj1CXHtyX04f1JXf/+Njln1a5nUcEQlzKvcI4fMZd144jJ4Zifzbkx+y50CN15FEJIyp3CNIWkIsM6aMZH9NPdc9tYImjb+LyDdQuUeYgd3SuH3Ssby/tYwdZdVexxGRMKVyj0Dnjcjj8rG9+Xx/DaWVdW1+n4seWsxFDy1ux2QiEi5U7hHq1rMHkRLvZ0txBRt3H/A6joiEGZV7hIrz++ifm0KMz5j6t+WUV9d7HUlEwojKPYJ9UfA791Zxw9MraGzSDlYRaaZy99Dsq8cy++qxQb1HakIst00YzIL1xfx5nq4gKSLN/F4HkOBNPi6fj3aVc/9bmxncI52zhnb3OpKIeExb7lHAzPj1uYMpzO/Cz+as4pPP93sdSUQ8pnKPEvH+GGZcNpKUeD9Tn1jOvqq2HyIpIpFP5R5FctMSmDFlJJ+X1zB9lnawinRmKvcoU5ifwW8mDmbhxhL++NonHfq1dBKUSPjSDtUodPHofNbuKueht7cwuEc65w7r4XUkEQkxbblHqV+dM5jvFGTw78+uYt0u7WAV6WxU7lEqzu/jgckj6ZIYx9S/LaMsiGvQiEjkCarczewGM1trZh+Z2Y2BaZlmNs/MNgY+ZrRPVDlSOanxPDRlJHsO1HLdUx/S0NjkdSQRCZE2l7uZDQGuAkYDw4BzzKw/cAsw3znXH5gf+Fw8MqxXF35/3hDe21zK7a927A5WEQkfwWy5HwMscc5VOecagLeB84GJwOOBZR4HzgsuogTrglG9uOL4Av767lZeWLHT6zgiEgLBlPta4CQzyzKzJOAsoBfQ1Tn3GUDgY25LLzazqWa2zMyWFRcXBxFDWuPWs4/huD6Z3PLcGtYWlXsdR0Q6WJvL3Tn3MfA/wDzgX8AqoOEIXj/TOTfKOTcqJyenrTGklWJjfNw/uZCs5DimPrGMkoparyOJSAcKaoeqc+4R51yhc+4koAzYCOw2s+4AgY97go8p7SE7JZ6HpoyitLKOaU9+qHuwikSxYI+WyQ18zAcmAbOAl4DLA4tcDswN5mtI+xraM53bfzCUpVvL2F5W5XWcoOgMWZFvFuwZqs+ZWRZQD0xzzu01s9uBZ8zsSmA7cEGwIaV9nT+iJ2uL9vPIu1tJjvPuJOUvijnYa9qLyNcF9T/bOTeuhWmlwPhg3lc63i/OHMicZTvYWlLJ/I93M/6Yrl5HEpF2pDNUOyl/TPMt+pLiYrj6b8uZu7LI60gi0o504bBOzB/jY2D3NGJjjBtnr2R/dT1TxhZ4HUtE2oG23Ds5v8947MejGT+wK7+c+xH3zt+I01E0IhFPW+4RrL12RCbExjDjskL+/dnV3DlvA/uq67n1rGPw+axd3l9EQk/lLkDzEM0dFwwjLTGWR97dSnl1PbdPGoo/Rn/ciUQilbsc5PMZt00YREZSHHe9sYH91fXcc8kIEmJjvI4mIkdIm2XyFWbGDd/tz20TBvH6ut385LEPqKht9VUlRCRMqNylRT8+oQ9/vnAYS7eWMfnhJezVzT5EIorKXb7RpMKezLhsJB9/foALH1rM5+U1XkcSkVZSucu3On1QVx7/8Wg+K6/hBw++x6cllV5HEpFWULnLYY3tm8VTVx1HVV0DP5yxWDfcFokAKndplWN7dmHONWOJjTEumrmYZZ+WeR1JRL6Fyl1arV9uKnOuGUt2SjyXPbKUfVXaySoSrlTuckR6ZiQx55qxHJWdwobdFZTqjk4iYUnlLkcsOyWep68eQ0q8n03Fldw8e6WOpBEJMyp3aZO0hFgGdkule3oCr6z+jFPvWMDdb2ykuq7R62ghoztBSThTuUub+XxGfmYS8396MqcNzOWuNzZw2p0LeHFFEU1NurKkiJdU7hK0XplJ3D+5kGeuHktWShw3zl7JpAffY/m2vV5H+1ba8pZopnKXdjO6TyYvTTuROy4Yxq591fzgwfe4ftYKivZVex1NpNNRuUu78vmMH47syVs/O4Xpp/XjtY8+57Q7FnDn6+up1AXIREJG5S4dIjnez0+/dzRv/uwUvj+4G/e+uYlT71jAnGU7NB4vEgIqd+lQeV0SueeSETx37fH06JLIz59dzcT7F/H+Vp3hKtKRdLOOTqy9btPXGiN7Z/D8tcfz8upd3P7qJ1z40GIyk2LplZkUsgwinYnKXULG5zMmDs/je4O68fDCLfzljQ2U7SznhNvfpCA7iT7ZyRRkJdMnu/nRKzOJWN3mT6RNVO4ScolxMVw/vj9vfbKH4gO1jCrIYGtpFS+t3MX+mv/b6RrjM3pmJH6t9PtkJ9OjS6KHayAS/lTu4pk4v4+8jET+cvEIAJxz7K2qZ2tJJVtLKvm0pJKtpZVsLa7k/a1lVH3p7Ne4GB8+HyTF+dlWWknvrGSvVkMkLKncJWyYGZnJcWQmxzGyd8ZX5jnn2HOg9v9Kv6SSZ5btoLy6ngn3vsvdF4/g1IG5HiWPXF+cxBXK/S8SGip3iQhmRte0BLqmJTDmqCwAVu7YR019I/WNjp88/gHXn9afG8b3x+czj9O2nspVOor2VklES4iN4blrj+f8EXncPX8jVz7+AeVV9V7HEvGcyl0iXmJcDHdeMIzfnjeEdzeVMOG+d/loV7nXsUQ8pXKXqGBmTBnTm6enjqW2oZFJD7zH8x/u9DqWiGdU7hJVRvbO4JXp4xjeqws3P7OKX81dS11Dk9exREJO5S5RJyc1nif/33FcNa4PTyzexsUzF+tOUdLpqNwlKvljfNx69iDuv7SQTz4/wDn3vsuSLaVexxIJGZW7RLWzj+3O3GknkJbgZ/Jfl/LXhVtwTlellOincpeo179rKnOvO4HvHpPL7/7xMdNnrdC15SXq6SQm6RRSE2KZcdlIZry9hT+99gkbdh8gITaGxNgYr6OJdIigttzN7CYz+8jM1prZLDNLMLPHzGyrma0MPIa3V1iRYJgZ157Slyd+chwlFXWsLSqnrLIuoodpdB9Y+SZtLnczywOuB0Y554YAMcDFgdk/d84NDzxWtkNOkXZzYv9sXp5+IomxMWzcU8HYP7zJjU+vYPYH29leWhXRZR9p9Mup4wQ7LOMHEs2sHkgCdgUfSaTj5XVJZFD3NEoqahmcl867m0p4ceWug/PGHJXF2L7NjzxdXvgbeX1tnGC/fqTn/zZtLnfnXJGZ3QFsB6qB151zr5vZpcDvzexXwHzgFudc7aGvN7OpwFSA/Pz8tsYQaTOfz8hNS+C+SwtxzrFpTwWLt5SyeHMpb36ym+cCZ7jmZyYxNlD2Y47Kolt6gsfJRQ6vzeVuZhnARKAPsA+YY2aXAb8APgfigJnAfwC/OfT1zrmZgfmMGjVKfweLp8yM/l1T6d81lR+NLaCpybF+9wEWby5l8ZZSXl37GbOX7QCgT3YyY47KorSilrTEWI+Ti7QsmGGZ7wJbnXPFAGb2PHC8c+7vgfm1ZvYo8LMgM0qYiubL1Pp8xjHd0zimexo/ObEPjU2Ojz/bf7DsX161i4rA4ZR3zdvA9eP7ExNBlxqW6BdMuW8HxphZEs3DMuOBZWbW3Tn3mZkZcB6wth1yingqxmcMyUtnSF46V510FA2NTUy8fxGfl9dw9/yNLNlSyt0Xj9CQjYSNNh8t45xbCjwLfAisCbzXTOBJM1sTmJYN/K4dcoqEFX+Mj5R4P/1yU7jzgmGsKSrnrHsW8tYne7yOJiEUzkf7BHW0jHPuNuC2QyafFsx7ikSaH4zsyfD8Lkx78kN+/NgHXDWuDz///kDi/DoBXLyjnz6RdtA3J4UXp53Aj8b25uGFW7lgxntsL63yOpZ0Yip3kXaSEBvDbyYOYcZlhWwtqeTsexbyymqd+iHeULmLtLMzhnTnH9ePo1/XFK57agW/eH4NNfWNXseSTkblLtIBemUm8czVY7nm5L7Men87E+9bxMbdB7yOJZ2Iyl08M/vqsVF9rHxsjI9bzhzI4z8ZTUlFLRPue5dnPtiha9dISKjcRTrYyQNyePWGcYzsncG/P7eaG2ev5EBNvdex2LO/hr1VdbrHbJTS9dxFQiA3LYEnfnIcDy7YxJ/nbWDVjn3ce0lhSDOUV9ezZEsp720qYdHmUjbtqTg474y/vMMpR+dyytE5jOydQWyMtvsincpdJERifMZ1p/XnuKOyuH7WCiY9uIju6QlkJsXR0NiEv50LtbqukWXbyli0qZT3NpewtqicJgeJsTF8p08mF4zsyQsriqisbaBLUix/XbiFGW9vJiXezwn9sjjl6FxOHpBDD10VMyKp3EVC7DsFmfzz+nH8/NnVvPHxbraXVTPwl/+iR5dEemUmkp+ZRM+MJHplJpGfmUSvjEQyk+NovqLHN2tobGLVzvLAlnkJH27bR11jE36fMSK/C9NP68/xfbMYkZ9x8ASrNz/ZQ3piLE9PHcuBmnoWbSrl7Q17WLC+mNc+2g3AgK4pzVv1A3IYVZCpk7MihMpdIlYk74zNSI7j4R+N5Ox7FlJd38RZQ7uxo6ya7WVVzFu3m5KKuq8snxwXQ69A6ednJh38JXCgpp6K2kaufOwDlm4tO3gxs0Hd07j8+N4c3y+b0QWZJMcf/r96akIsZwzpxhlDuuGcY+OeChasby76RxdtZeY7W0iOi+H4ftmcPCCHU47O6ZDvjbQPlbuIR8yM1IRYUhPg598f+JV5lbUN7NzbXPY7yqrYXlbFzr3NzxdtKqH6kOPmY3zGxOE9OKFfNmOOyiIzOS7obAO6pjKgaypTT+pLRW0DizeXHiz7eeuat+oTYn1kJcfzaUklBdnJQX1NaV8qd5EwlBzv5+huqRzdLfVr85xzlFbWsb2siv94djXJ8TG8OO3EDs2TEu/n9EFdOX1QV5xzbC6uYMH6Yu6ev5GifdWccscCCvO7cP6IPM45tgcZQf5ykeCp3EUijJmRnRJPdkp80Fvobf36/XJT6Zebyrx1u6ltaOT7g7vzwoqd/HLuR/zmlXWcPCCXSYV5nDYwl4TYmJBnFJW7iAQp3h/Dtaf05ZqTj+Ljzw7wwoqdzF25izc+3k1qgp+zh3bnvBF5jC7IxKcbmoSMyl06rUjeIRuOzIxBPdIY1GMQt5x5DO9tLuGFFUW8tGoXT3+wg7wuiUwc3oNJhXn0y/36cJO0L5W7iLS7GJ8xrn8O4/rn8LvzGpi3bjfPf1jEjLc388CCzQzJS+P8ET2pa2jSoZUdROUuIh0qKc7PxOF5TByex54DNby86jNeXFHEb19ZB0BcjI9LZi6hd1YSvbOS6Z3VfLhn76wkUhOi+wbk1XWNxHfQLzeVu4iETG5qAlee2IcrT+zDpj0HuOLRD6iua6S2oZF563ZTWvnV4/uzkuMOln5+ZhIF2UnkZyZTkJXkyc7k9vJpSSV3z9/I6qJy8jOTOuRrqNxFxBP9clPJC1za4Iv9Hwdq6tlW2nxc/7bSKraVVrKttIqlW0p5cWURX76gZkq8nybniDFjyiNLiff7iPfHEO/3Eef3NX8eGxOYHpgX+3/P4/w+9lXVhfSvg6J91dw7fyNzlu8kNsbonp5AdkrH/JJSuYtI2EhNiGVIXjpD8tK/Nq+mvpGde6sPFv620krmrtxFo3NU1DZQWtFEXWMTtQ2N1NY3UdsQeN7QxLddZdln8Ivn1zD5uPwWv2572L2/hvvf2sTT7+8AYMqY3vzbqX2Z/tSKDvl6oHIXkQiREBtDv9wU+uWmHJz2yefNN0D5tiOfnHPUNzpqGxqpa/ii9JuL/8anV1JSUcsLK3Yy6/3tDM1L55LR+Zw7vAcprbhkw+GUVtQy4+3NPLF4G41Njgu/04vrTu0XkouxqdxFJKqZGXF+a/GonPTEWNITY5n5o1HMXVnEU0u3858vrOH3/1jHucPzuHR0PkN7HvnWfHlVPQ8v3ML/LtpKTX0j54/oyQ3j+5Of1THj6y1RuYtIp5eeGMuPxhYwZUxvVuzYx6yl2w9uzQ/JS+PS0b1btTV/oKaeRxd9ysMLt3CgpoEJw3pww/j+X/lrI1RU7iIiAWZGYX4GhfkZ/Nc5g76yNf+7f6xj4vAeXDq699e25qvrGnli8afMeHsze6vq+d6grtx0+gCO6Z7mzYqgchdpM53hGt1a3povYtb7OxiSl8Ylo/Opb2yitKKOcX98i5KKWk45OoebTx/AsT27eB1f5S4i8m2+vDX/ywmDmLuiiCeXbufWF9YeXGbMUZnMuKyQUQWZHib9KpW7iEgrpSXEMmVsAZeN6c3KHfuY9uSHpAXuZBVuVO4iIkfIzBiRn0GvDjq7tD3oij0iIlFIW+4i0mbaqRy+VO4iEUzlKt9EwzIiIlFI5S4iEoU0LCPSiWlYJ3ppy11EJAqp3EVEopCGZUQ8pGER6ShBbbmb2U1m9pGZrTWzWWaWYGZ9zGypmW00s9lmFrk3OhQRiVBtLnczywOuB0Y554YAMcDFwP8Adznn+gN7gSvbI6iIiLResGPufiDRzPxAEvAZcBrwbGD+48B5QX4NERE5Qm0ud+dcEXAHsJ3mUi8HlgP7nHMNgcV2Anktvd7MpprZMjNbVlxc3NYYIiLSgmCGZTKAiUAfoAeQDJzZwqIt3nfcOTfTOTfKOTcqJyenrTFERKQFwRwt811gq3OuGMDMngeOB7qYmT+w9d4T2BV8TBGJRp39aKGOXP9gxty3A2PMLMnMDBgPrAPeAn4YWOZyYG5wEUVE5EgFM+a+lOYdpx8CawLvNRP4D+BmM9sEZAGPtENOERE5AkGdxOScuw247ZDJW4DRwbyviEhrdPZhnW+jM1RFpNOK5l8OuraMiEgUUrmLiEQhlbuISBRSuYuIRCGVu4hIFFK5i4hEIZW7iEgU0nHuIiJtFM7HyWvLXUQkCqncRUSikMpdRCQKqdxFRKKQyl1EJAqp3EVEopDKXUQkCqncRUSikMpdRCQKmXPO6wyYWTGwrY0vzwZK2jFOpNH6d+71B30POvP693bO5bQ0IyzKPRhmtsw5N8rrHF7R+nfu9Qd9Dzr7+n8TDcuIiEQhlbuISBSKhnKf6XUAj2n9pbN/Dzr7+rco4sfcRUTk66Jhy11ERA6hchcRiUIRU+5mdoaZrTezTWZ2Swvz481sdmD+UjMrCH3KjtOK9b/ZzNaZ2Wozm29mvb3I2VEOt/5fWu6HZubMLKoOjWvN+pvZhYGfgY/M7KlQZ+xIrfj5zzezt8xsReD/wFle5AwrzrmwfwAxwGbgKCAOWAUMOmSZfwNmBJ5fDMz2OneI1/9UICnw/NrOtv6B5VKBd4AlwCivc4f4378/sALICHye63XuEK//TODawPNBwKde5/b6ESlb7qOBTc65Lc65OuBpYOIhy0wEHg88fxYYb2YWwowd6bDr75x7yzlXFfh0CdAzxBk7Umv+/QF+C/wRqAlluBBozfpfBdzvnNsL4JzbE+KMHak16++AtMDzdGBXCPOFpUgp9zxgx5c+3xmY1uIyzrkGoBzICkm6jtea9f+yK4FXOzRRaB12/c1sBNDLOfdKKIOFSGv+/QcAA8xskZktMbMzQpau47Vm/X8NXGZmO4F/AtNDEy18+b0O0EotbYEfegxna5aJVK1eNzO7DBgFnNyhiULrW9ffzHzAXcAVoQoUYq359/fTPDRzCs1/tS00syHOuX0dnC0UWrP+lwCPOefuNLOxwN8C69/U8fHCU6Rsue8Een3p8558/c+ug8uYmargxpkAAAFQSURBVJ/mP83KQpKu47Vm/TGz7wK3Auc652pDlC0UDrf+qcAQYIGZfQqMAV6Kop2qrf35n+ucq3fObQXW01z20aA1638l8AyAc24xkEDzBcU6rUgp9w+A/mbWx8ziaN5h+tIhy7wEXB54/kPgTRfYuxIFDrv+gWGJh2gu9mgab4XDrL9zrtw5l+2cK3DOFdC8z+Fc59wyb+K2u9b8/L9I8051zCyb5mGaLSFN2XFas/7bgfEAZnYMzeVeHNKUYSYiyj0whn4d8BrwMfCMc+4jM/uNmZ0bWOwRIMvMNgE3A994uFykaeX6/wlIAeaY2UozO/SHP2K1cv2jVivX/zWg1MzWAW8BP3fOlXqTuH21cv1/ClxlZquAWcAVUbRx1ya6/ICISBSKiC13ERE5Mip3EZEopHIXEYlCKncRkSikchcRiUIqdxGRKKRyFxGJQv8f4il8pqAO9eoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 59 ms, total: 1min 26s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accs = []\n",
    "accs_std = []\n",
    "\n",
    "for noise in np.arange(0, 1, 0.05):\n",
    "    accs_run = []\n",
    "    for run in range(50):\n",
    "        # Generate sample and approximate values to 0 and 1\n",
    "        student_performance = generate_sample(noise)\n",
    "        student_performance[student_performance > 0.5] = 1\n",
    "        student_performance[student_performance < 0.5] = 0\n",
    "        \n",
    "\n",
    "#         Run tensor factorization\n",
    "        student_performance_pred_run, error_run, error_total_run = als_tensor_factorization(\n",
    "            student_performance, n_concepts=2, init=3, max_iter=50)\n",
    "        \n",
    "\n",
    "#         Get best run results\n",
    "        best_run = np.unravel_index(error_run.argmin(), error_run.shape)\n",
    "        best_student_performance_pred = student_performance_pred_run[best_run]\n",
    "        best_student_performance_pred[best_student_performance_pred > 0.5] = 1\n",
    "        best_student_performance_pred[best_student_performance_pred < 0.5] = 0\n",
    "        \n",
    "\n",
    "#         Calculate accuracy\n",
    "        acc = 100*(np.logical_not(np.logical_xor(\n",
    "            student_performance, best_student_performance_pred)).sum())/(\n",
    "            student_performance.shape[0]*student_performance.shape[1]*student_performance.shape[2])\n",
    "        accs_run.append(acc)\n",
    "\n",
    "    accs.append(np.asarray(accs_run).mean())\n",
    "    accs_std.append(np.asarray(accs_run).std())\n",
    "    \n",
    "plt.errorbar(np.arange(0, 1, 0.05), accs, yerr=accs_std)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accs = []\n",
    "accs_std = []\n",
    "for noise in np.arange(0, 1, 0.05):\n",
    "    accs_run = []\n",
    "    for run in range(50):\n",
    "        # Generate sample and approximate values to 0 and 1\n",
    "        student_performance, student_performance_t = generate_sample(noise)\n",
    "        student_performance[student_performance > 0.5] = 1\n",
    "        student_performance[student_performance < 0.5] = 0\n",
    "\n",
    "        # Run tensor factorization\n",
    "        student_performance_pred_run, error_run, error_total_run = als_tensor_factorization(\n",
    "            student_performance, n_concepts=2, init=3, max_iter=50)\n",
    "\n",
    "        # Get best run results\n",
    "        best_run = np.unravel_index(error_run.argmin(), error_run.shape)\n",
    "        best_student_performance_pred = student_performance_pred_run[best_run]\n",
    "        best_student_performance_pred[best_student_performance_pred > 0.5] = 1\n",
    "        best_student_performance_pred[best_student_performance_pred < 0.5] = 0\n",
    "\n",
    "        # Calculate accuracy\n",
    "        acc = 100*(np.logical_not(np.logical_xor(\n",
    "            student_performance, best_student_performance_pred)).sum())/(\n",
    "            student_performance.shape[0]*student_performance.shape[1]*student_performance.shape[2])\n",
    "        accs_run.append(acc)\n",
    "    accs.append(np.asarray(accs_run).mean())\n",
    "    accs_std.append(np.asarray(accs_run).std())\n",
    "    \n",
    "plt.errorbar(np.arange(0, 1, 0.05), accs, yerr=accs_std)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.zeros((N_QUESTIONS, N_STUDENTS, N_ATTEMPTS))\n",
    "for attempt in range(N_ATTEMPTS):\n",
    "    diff[:, :, attempt] = student_performance[:, :, attempt] - best_student_performance_pred[:, :, attempt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.898979485566356"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.power(diff, 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
